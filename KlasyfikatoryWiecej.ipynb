{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opis bardziej zaawansowanych metod tworzenia i testowania klasyfikatorów (prezentacja uzupełniająca bez zadań)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikator oparty na lesie losowym\n",
    "\n",
    "Często występującym problemem związanym z drzewami decyzyjnymi jest to, że mogą one nadmiernie\n",
    "dopasować dane uczące. To sprawiło, że zaczęto szerzej stosować metodę o nazwie losowego\n",
    "lasu. W przypadku losowego lasu następuje wytrenowanie wielu drzew decyzyjnych, ale każde z nich\n",
    "otrzymuje tylko próbki początkowe obserwacji (na przykład losowo wybrane próbki obserwacji ze\n",
    "zwracaniem, dopasowane do początkowej liczby obserwacji), a każdy węzeł analizuje jedynie podzbiór\n",
    "cech podczas wybierania najlepszego sposobu rozgałęzienia. Las losowych drzew decyzyjnych\n",
    "(stąd nazwa algorytmu) głosuje, aby ustalić prognozowaną klasę.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Dokładnośc klasyfikacji= 0.7716049382716049\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.83      0.80        92\n",
      "           2       0.75      0.70      0.73        70\n",
      "\n",
      "    accuracy                           0.77       162\n",
      "   macro avg       0.77      0.76      0.77       162\n",
      "weighted avg       0.77      0.77      0.77       162\n",
      "\n",
      "====== MACIERZ POMYŁEK (confusion matrix) +=========\n",
      "[[76 16]\n",
      " [21 49]]\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "#Parametry tworzenia lasu losowego\n",
    "\n",
    "my_criterion = \"gini\" #Kryterium podziału węzła drzewa podczas budowy drzewa: 'gini', 'entropy' \n",
    "\n",
    "#Maksymalna głebokość drzewa. Wartość None powoduje, że drzewo będzie się rozrastało aż do\n",
    "#chwili, gdy wszystkie liście będą jednorodne (składające się z obiektów mających taką samą decyzję). \n",
    "#Z kolei wartość w postaci liczby całkowitej praktycznie oznacza „przycięcie” drzewa do podanej głębokości\n",
    "my_max_depth = 5 \n",
    "\n",
    "#Minimalna liczba obserwacji w węźle, zanim nastąpi jego rozgałęzienie. Jeżeli wartością jest\n",
    "#liczba całkowita, określa czyste minimum, zaś liczba zmiennoprzecinkowa określa wielkość\n",
    "#procentową wszystkich obserwacji (domyślnie 2).\n",
    "my_min_samples_split = 10 \n",
    "\n",
    "#Minimalna liczba obserwacji wymaganych do umieszczenia na liściu (domyślnie 1).\n",
    "my_min_samples_leaf = 2\n",
    "\n",
    "#Maksymalna liczba liści.\n",
    "my_max_leaf_nodes = 30\n",
    "\n",
    "#Minimalny wymagany spadek niejednorodności (zwieksenie czystości), aby został utworzoby podział węzła\n",
    "my_min_impurity_decrease = 0.02\n",
    "\n",
    "\n",
    "\n",
    "#Maksymalna liczba cech uwzględnianych w każdym węźle. Domyślnie będzie to sqrt(p) cech, gdzie p\n",
    "#to całkowita liczba cech.\n",
    "my_max_features = 10\n",
    "\n",
    "#Określenie, czy próbki mają być ze zwracaniem. Wartością domyślną tego parametru jest True.\n",
    "my_bootstrap = True\n",
    "\n",
    "#Określenie liczby drzew decyzyjnych do utworzenia. Wartością domyślną tego parametru jest 100.\n",
    "my_n_estimators = 20\n",
    "\n",
    "#Okreslenie liczby wykorzystywanych rdzeni podczas obliczeńn_jobs. Przypisanie mu wartości -1\n",
    "#pozwala na użycie wszystkich dostępnych rdzeni procesora.\n",
    "my_n_jobs = -1\n",
    "\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych\n",
    "\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu lasu losowego\n",
    "model = RandomForestClassifier(criterion=my_criterion,\n",
    "                               max_depth=my_max_depth,\n",
    "                               min_samples_split=my_min_samples_split,                                \n",
    "                               min_samples_leaf = my_min_samples_leaf,\n",
    "                               max_leaf_nodes = my_max_leaf_nodes,\n",
    "                               min_impurity_decrease = my_min_impurity_decrease,\n",
    "                               max_features = my_max_features,\n",
    "                               bootstrap = my_bootstrap,\n",
    "                               n_estimators = my_n_estimators,    \n",
    "                               random_state=0, n_jobs=my_n_jobs)\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n",
    "print(\"====== MACIERZ POMYŁEK (confusion matrix) +=========\")\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Wagi cech: [0.08535226 0.03169312 0.112757   0.08153562 0.07740821 0.01067269\n",
      " 0.02389731 0.12172662 0.06066722 0.10704558 0.04712584 0.11967151\n",
      " 0.12044702]\n",
      "wagi_cech_malejaco: [ 7 12 11  2  9  0  3  4  8 10  1  6  5]\n",
      "['wiek', 'plec', 'typ_bolu_klatka', 'cisnienie_krwi_spoczynek', 'cholesterol_we_krwi', 'cukier_we_krwi', 'wynik_EKG_spoczynek', 'ilosc_uderzen_serca', 'bol_klatka_wysilek', 'max_obnizka_ST', 'przebieg_ST_szczyt', 'zwapnienia_miazdzycowe', 'proba_tal']\n",
      "['ilosc_uderzen_serca', 'proba_tal', 'zwapnienia_miazdzycowe', 'typ_bolu_klatka', 'max_obnizka_ST', 'wiek', 'cisnienie_krwi_spoczynek', 'cholesterol_we_krwi', 'bol_klatka_wysilek', 'przebieg_ST_szczyt', 'plec', 'wynik_EKG_spoczynek', 'cukier_we_krwi']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Selekcja cech za pomocą lasu losowego\n",
    "\n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu lasu losowego\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(features, np.ravel(labels)) #Uczenie klasyfikatora \n",
    "\n",
    "# Ustalenie wagi cechy.\n",
    "wagi_cech = model.feature_importances_\n",
    "\n",
    "print(\"Wagi cech:\",wagi_cech)\n",
    "\n",
    "# Posortowanie wagi cech w kolejności malejącej.\n",
    "wagi_cech_malejaco = np.argsort(wagi_cech)[::-1]\n",
    "\n",
    "print(\"wagi_cech_malejaco:\",wagi_cech_malejaco)\n",
    "\n",
    "nazwy_kolumn = list(features.columns.values)\n",
    "\n",
    "nazwy_kolumn_malejaco = [nazwy_kolumn[i] for i in wagi_cech_malejaco]\n",
    "\n",
    "print(nazwy_kolumn)\n",
    "print(nazwy_kolumn_malejaco)\n",
    "\n",
    "plt.figure()\n",
    "# Utworzenie tytułu wykresu.\n",
    "plt.title(\"Waga cech\")\n",
    "# Dodanie słupków.\n",
    "plt.bar(range(features.shape[1]), wagi_cech[wagi_cech_malejaco])\n",
    "\n",
    "plt.xticks(range(features.shape[1]), nazwy_kolumn_malejaco, rotation=90)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Przed sortowaniem:\n",
      "('wiek', 0.08850559495235177)\n",
      "('plec', 0.031899697778323195)\n",
      "('typ_bolu_klatka', 0.12193057070376888)\n",
      "('cisnienie_krwi_spoczynek', 0.07143776029500885)\n",
      "('cholesterol_we_krwi', 0.09547204465402287)\n",
      "('cukier_we_krwi', 0.006514866769042664)\n",
      "('wynik_EKG_spoczynek', 0.025644123728909188)\n",
      "('ilosc_uderzen_serca', 0.12590089498168455)\n",
      "('bol_klatka_wysilek', 0.04399510637275356)\n",
      "('max_obnizka_ST', 0.10363929227050006)\n",
      "Posortowane:\n",
      "('proba_tal', 0.1334260930033991)\n",
      "('ilosc_uderzen_serca', 0.12590089498168455)\n",
      "('typ_bolu_klatka', 0.12193057070376888)\n",
      "('max_obnizka_ST', 0.10363929227050006)\n",
      "('zwapnienia_miazdzycowe', 0.10061050178462823)\n",
      "('cholesterol_we_krwi', 0.09547204465402287)\n",
      "('wiek', 0.08850559495235177)\n",
      "('cisnienie_krwi_spoczynek', 0.07143776029500885)\n",
      "('przebieg_ST_szczyt', 0.051023452705606945)\n",
      "('bol_klatka_wysilek', 0.04399510637275356)\n"
     ]
    }
   ],
   "source": [
    "#Własna selekcja cech za pomocą lasu losowego\n",
    "\n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu lasu losowego\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(features, np.ravel(labels)) #Uczenie klasyfikatora \n",
    "\n",
    "# Ustalenie wagi cechy.\n",
    "wagi_cech = model.feature_importances_\n",
    "kolumny = list(features.columns.values)\n",
    "\n",
    "kolumnyWagi = []\n",
    "for i in range(0,len(kolumny)):\n",
    "    para = (kolumny[i],wagi_cech[i])\n",
    "    kolumnyWagi.append(para)\n",
    "\n",
    "    \n",
    "print(\"Przed sortowaniem:\")\n",
    "for i in range(0,10):\n",
    "    para = kolumnyWagi[i]\n",
    "    print(para)\n",
    "\n",
    "    \n",
    "def objCompareFunc(element):\n",
    "    return element[1]\n",
    "\n",
    "kolumnyWagi.sort(reverse=True,key=objCompareFunc)    \n",
    "\n",
    "print(\"Posortowane:\")\n",
    "for i in range(0,10):\n",
    "    para = kolumnyWagi[i]\n",
    "    print(para)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikator AdaBoost\n",
    "\n",
    "W losowym lesie zespół (grupa) losowych drzew decyzyjnych prognozuje wektor docelowy. Podejście\n",
    "alternatywne i często oferujące większe możliwości nosi nazwę wzmocnienia (ang. boosting).\n",
    "Jedna z form wzmocnienia to AdaBoost, w której następuje iteracyjne wytrenowanie serii słabych\n",
    "modeli, często płytkich drzew decyzyjnych nazywanych pniami. W trakcie każdej iteracji nadawany\n",
    "jest większy priorytet obserwacjom poprzednio nieprawidłowo prognozowanego modelu. Oto\n",
    "dokładne wyjaśnienie sposobu działania techniki AdaBoost.\n",
    "\n",
    "1. Przypisanie każdemu obiektowi treningowemu $x$ wartości wagi początkowej wyrażonej wzorem $w_x=\\frac{1}{n}$, gdzie $n$ to liczba wszystkich obiektów treningowych.\n",
    "\n",
    "2. Wytrenowanie „słabego” modelu na podstawie danych.\n",
    "\n",
    "3. Dla każdego obiektu $x$ jeżeli słaby model prawidłowo prognozował $x$, wówczas zwiększana jest wartość $w_x$;\n",
    "w przeciwnym przypadku zmniejszana jest wartość $w_x$.\n",
    "\n",
    "4. Wytrenowanie nowego słabego modelu, w którym obserwacje o większej wartości $w_x$ mają\n",
    "przypisany większy priorytet.\n",
    "\n",
    "5. Powtarzanie kroków 4. i 5. dopóty, dopóki dane nie będą doskonale prognozowane lub nie\n",
    "nastąpi wytrenowanie zdefiniowanej liczby słabych modeli.\n",
    "\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Dokładnośc klasyfikacji= 0.8209876543209876\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.84      0.84        92\n",
      "           2       0.79      0.80      0.79        70\n",
      "\n",
      "    accuracy                           0.82       162\n",
      "   macro avg       0.82      0.82      0.82       162\n",
      "weighted avg       0.82      0.82      0.82       162\n",
      "\n",
      "====== MACIERZ POMYŁEK (confusion matrix) +=========\n",
      "[[77 15]\n",
      " [14 56]]\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "#Główne parametry \n",
    "\n",
    "#Liczba modeli trenowanych iteracyjnie.\n",
    "my_n_estimators = 30\n",
    "\n",
    "#Wkład poszczególnych modeli w wagę; wartość domyślna wynosi 1. Zmniejszenie\n",
    "#wartości tego parametru spowoduje niewielkie zmniejszenie lub zwiększenie wagi, co wymusi\n",
    "#wolniejsze trenowanie modelu (czasami skutkiem będzie lepsza wydajność).\n",
    "my_learning_rate = 1\n",
    "\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych\n",
    "\n",
    "\n",
    "#Utworzenie obiektu przykładowego...\n",
    "model = AdaBoostClassifier(n_estimators=my_n_estimators,\n",
    "                           learning_rate=my_learning_rate,\n",
    "                           random_state=0)\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n",
    "print(\"====== MACIERZ POMYŁEK (confusion matrix) +=========\")\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maszyna wektorów nośnych\n",
    "\n",
    "\n",
    "*Maszyna wektorów nośnych* lub inaczej *maszyna wektorów podpierających* (ang. Support Vector Machine, SVM) to abstrakcyjna maszyna, która działa jako klasyfikator. Podstawowym pojęciem na którym opiera się maszyna wektorów nośnych jest hiperpłaszczyzna, a dokładnie \n",
    "dzielenie przestrzeni obiektów w oparciu o hiperpłaszczyzny. Z formalnego\n",
    "punktu widzenia hiperpłaszczyzna to podprzestrzeń n–1 wymiarowa w przestrzeni n-wymiarowej. Na przykład jeśli chcemy podzielić\n",
    "przestrzeń dwuwymiarową (płaszczyznę), wówczas używamy jednowymiarowej hiperpłaszczyzny (linii prostej).\n",
    "Natomiast, jeśli chcemy podzielić przestrzeń trójwymiarową, używamy dwuwymiarowej hiperpłaszczyzny (płaszczyzny).\n",
    "\n",
    "Maszyna wektora nośnego klasyfikuje dane przez wyszukanie hiperpłaszczyzny maksymalizującej\n",
    "margines między klasami w danych uczących. W przypadku dwuwymiarowym wraz z dwiema klasami\n",
    "za hiperpłaszczyznę można uznać najdłuższy prosty „pas” (na przykład linia wraz z marginesami)\n",
    "oddzielający te dwie klasy.\n",
    "\n",
    "Choć podstawowym sposobem oddzielania obiektów z różnych klas od siebie  w metodzie SVM jest konstruowanie hiperpłaszczyzn liniowych (np. lini prostych, płaszczyzn) to jednak to podejście często nie daje dobrych wyników, bo obiekty nie dają się w ten sposób rozdzielić ze względu na swoje położenie. Dlatego w metodzie SVM stosuje się różne metody przekształcania tych hiperpłaszczyz, aby stały się krzywymi lub powierzchniami, które lepiej rozdzielą \n",
    "obiekty z różnych klas. Podstawowym narzedziem do tego jest tzw. *jądro*, które można traktować jako funkcję agregującą podobieństwo pomiędzy parami obiektów. Dla przykładu, jeśli jądro oblicza się jako sumę iloczynów wartości poszczególnych atrybutów, to jest to *jądro liniowe*. Natomiast, jeśli we wzorze na jądro pojawia się potęgowanie takiej sumy, to jest to *jądro wielomianowe*, przy czym ważny jest tutaj wykładnik stosowanej potęgi. \n",
    "Wreszcie, gdy potęga sumy iloczynów wartości poszczególnych atrybutów pojawia się w wykładniku potegi liczby e, to jądro nazywa się *jądrem radialnym*. W tym przypadku we wspomnianym wykładniku pojawia się parametr gamma, który jest ważnym parametrem jądra radialnego.   \n",
    "\n",
    "Intuicyjnie można stwierdzić, że poszczególne rodzaje jądra rozsuwają niejako punkty lokalnie roziągając przestrzeń\n",
    "na różne sposoby, co powoduje, że wyznaczona hiperpłaszczyzna może je lepiej rozdzielić.\n",
    "\n",
    "Jednak hiperłaszczyzna w tak zmienionej przestrzeni może nie być już tworem liniowym, ale jest krzywą lub powierzchnią\n",
    "w przestrzeni atrybutów. Dlatego właśnie jest w stanie lepiej oddzielić od siebie obiekty z różnych klas.\n",
    "\n",
    "Warto dodać, że największe możliwości rozdzieleania od siebie obiektów z różnych klas ma SVM z jądrem radialnym i dlatego jest ono bardzo często używane.\n",
    "\n",
    "Przy wykorzystaniu klasy SVM z biblioteki scikit-learn jądro przeznaczone do użycia można wybrać za pomocą parametru `kernel`.\n",
    "\n",
    "Po wybraniu jądra trzeba zdefiniować jego odpowiednie opcje, takie jak np. wartość potęgi w jądrze wielomianowym (za pomocą parametru `degree`) i wartośc parametru `gamma` w jądrze radialnym. Konieczne jest również zdefiniowanie parametru kary `C`, który określa wysokość kary za błędną klasyfikację obiektu testowego, stosowaną\n",
    "do oceny klasyfikatora podczas jego tworzenia.\n",
    "\n",
    "Ponieważ istota działania jądra wiąże się z agregacją podobieństwa obiektów na róznych atrybutach, dobrze jest przed wyznaczeniem klasyfikatora dokonać standaryzacji atrybutów warunkowych.\n",
    "\n",
    "\n",
    "Nazwa maszyny wektorów nośnych wzięła się stąd, że hiperpłaszczyzna jest określana na podstawie\n",
    "względnie małej liczby obiektów treningowych, nazywanych wektorami nośnymi. Sa one wyliczane podczas \n",
    "konstruowania klasyfikatora. Hiperpłaszczyznę można\n",
    "zatem uznać za „prowadzoną” przez te wektory. Dlatego też wektory nośne mają ogromną wagę\n",
    "dla modelu. Jeżeli z danych usuniesz obserwację niebędącą wektorem nośnym, model nie ulegnie\n",
    "zmianie. Jeżeli jednak usuniesz wektor nośny, hiperpłaszczyzna nie będzie miała maksymalnego\n",
    "marginesu.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.8148148148148148\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.87      0.84        92\n",
      "           2       0.81      0.74      0.78        70\n",
      "\n",
      "    accuracy                           0.81       162\n",
      "   macro avg       0.81      0.81      0.81       162\n",
      "weighted avg       0.81      0.81      0.81       162\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy= 0.7407407407407407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.96      0.81        92\n",
      "           2       0.89      0.46      0.60        70\n",
      "\n",
      "    accuracy                           0.74       162\n",
      "   macro avg       0.79      0.71      0.71       162\n",
      "weighted avg       0.78      0.74      0.72       162\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy= 0.5679012345679012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      1.00      0.72        92\n",
      "           2       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.57       162\n",
      "   macro avg       0.28      0.50      0.36       162\n",
      "weighted avg       0.32      0.57      0.41       162\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "\n",
    "#Pokazani ewykresu danych\n",
    "vetor_labels = np.ravel(labels)\n",
    "\n",
    "\n",
    "#Tworzenie klasyfikatorów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=0)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "# Standaryzowanie cech.\n",
    "scaler = StandardScaler()\n",
    "features_train_stand = scaler.fit_transform(features_train)\n",
    "features_test_stand = scaler.fit_transform(features_test)\n",
    "\n",
    "#Opis wybranych parametrów\n",
    "\n",
    "# C - wartość kary za błędne klasyfikacje; zmniejszenie go zwiększa margines błędu, przez co akceptowalny jest \n",
    "# większy szum, ale model staje sie bardziej ogólny; ustawiać od 0.01 do 10\n",
    "\n",
    "# kernel - to wybrane jądro (np: 'linear','poly','rbf')\n",
    "\n",
    "# degree - jest używany tylko dla jądra wielomianowego ('poly') i określa stopień rozwinięcia wielomianowego;\n",
    "# ustawiać od 2 do 5\n",
    "\n",
    "# gamma - określa współczynik dla jądra 'rbf' i 'poly'; wysokie wartości prowadzą do większego dopasowania \n",
    "# do danych, ale mogą powodować nadmierne dopasowanie do danych (przeuczenie); ustawiać od 0.0001 do 1 \n",
    "\n",
    "\n",
    "svm1 = SVC(kernel=\"linear\", C=0.1, random_state=0)\n",
    "svm2 = SVC(kernel=\"poly\", C=0.1, gamma=0.1, degree=3)\n",
    "svm3 = SVC(kernel=\"rbf\", gamma=1, C=0.001,random_state=0)\n",
    "\n",
    "svm_list = []\n",
    "svm_list.append(svm1)\n",
    "svm_list.append(svm2)\n",
    "svm_list.append(svm3)\n",
    "\n",
    "\n",
    "for svm in svm_list:\n",
    "    model = svm.fit(features_train_stand, np.ravel(labels_train))\n",
    "    model.fit(features_train_stand, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "    labels_predicted = model.predict(features_test_stand) #Generowania decyzji dla części testowej\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "    print(\"Accuracy=\" ,accuracy)\n",
    "    report = classification_report(labels_test, labels_predicted)\n",
    "    print(report )\n",
    "    print(\"--------------------------------------------------------\")\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikator oparty na regresji logistycznej\n",
    "\n",
    "Klasyfikator oparty na regresji logistycznej działa podobnie jak inne metody probabilistyczne klasyfikacji \n",
    "obiektów, tzn. najpierw dla danego obiektu oszacowuje prawdopodobieństwa, że obiekt ten przynależy do \n",
    "poszczególnych klas decyzyjnych, a później wybiera klasę, która ma największe prawdopodobieństwo.\n",
    "\n",
    "Jeśli mamy tablicę decyzyjną T mającą atrybuty warunkowe $a_1$,.., $a_m$ i atrybut decyzyjny $d$ \n",
    "z wartościami $d_1$,..., $d_k$, to prawdopodobieństwo, że obiekt testowy $u=(u_1,...,u_m)$ należy do \n",
    "klasy decyyzjnej $d_i$ wyraża się wzorem:\n",
    "\n",
    "\n",
    "\n",
    "$$P(d_i|u_1,...,u_m) = \\frac{e^{\\beta_{0} + \\sum_{j=1}^{m} \\beta_i \\cdot u_j}}{\\sum_{l=1}^{k} e^{\\beta_{0} + \\sum_{j=1}^{m} \\beta_l \\cdot u_j}}$$\n",
    "\n",
    "\n",
    "gdzie parametry $\\beta_0, \\beta_1, ... \\beta_k$ są wyuczane z danych podczas konstrukcji klasyfikatora.\n",
    "\n",
    "Do tworzenia klasyfikatorów tą metodą dobrze jest użyć standaryzacji danych.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Dokładnośc klasyfikacji= 0.845679012345679\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.86        92\n",
      "           2       0.82      0.83      0.82        70\n",
      "\n",
      "    accuracy                           0.85       162\n",
      "   macro avg       0.84      0.84      0.84       162\n",
      "weighted avg       0.85      0.85      0.85       162\n",
      "\n",
      "====== MACIERZ POMYŁEK (confusion matrix) +=========\n",
      "[[79 13]\n",
      " [12 58]]\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "\n",
    "# Standaryzowanie cech.\n",
    "scaler = StandardScaler()\n",
    "features_train_stand = scaler.fit_transform(features_train)\n",
    "features_test_stand = scaler.fit_transform(features_test)\n",
    "\n",
    "# Utworzenie obiektu regresji logistycznej wykorzystującej technikę typu jeden przeciwko reszcie.\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Wytrenowanie modelu.\n",
    "model = logistic_regression.fit(features_train_stand, np.ravel(labels_train))\n",
    "\n",
    "model.fit(features_train_stand, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test_stand) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n",
    "print(\"====== MACIERZ POMYŁEK (confusion matrix) +=========\")\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie działania klasyfikatorów tworzonych różnymi metodami dla ustalonego zestawu parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.845679012345679 GaussianNB\n",
      "2. 0.8395061728395061 QuadraticDiscrim\n",
      "3. 0.8395061728395061 GradientBoosting\n",
      "4. 0.8333333333333334 RandomForest\n",
      "5. 0.8271604938271605 LogisticRegression\n",
      "6. 0.8024691358024691 Linear SVM\n",
      "7. 0.7962962962962963 BernoulliNB\n",
      "8. 0.7901234567901234 AdaBoost\n",
      "9. 0.7777777777777778 MLPClassifier\n",
      "10. 0.7654320987654321 DecisionTree\n",
      "11. 0.7345679012345679 Poly SVM\n",
      "12. 0.6728395061728395 KNN\n",
      "13. 0.5617283950617284 RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #Ignorowanie ostrzeżeń\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv')\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "#Podział tablicy na część treningową i testową\n",
    "data = train_test_split(features, labels, test_size=0.6, random_state=12345)\n",
    "features_train = data[0]\n",
    "features_test = data[1]\n",
    "labels_train = data[2]\n",
    "labels_test = data[3]\n",
    "\n",
    "#========DEFINIOWANIE MODELI i ich nazw ===============\n",
    "\n",
    "models = []\n",
    "modelNameList = []\n",
    "\n",
    "#Klasyfikator k najbliższych sąsiadów\n",
    "model = KNeighborsClassifier(n_neighbors=3,metric = 'euclidean')\n",
    "models.append(model)\n",
    "modelNameList.append(\"KNN\")\n",
    "\n",
    "#Naiwny Bayes traktujący atrybuty jako atrybuty z ciągłymi wartościami (dobry dla numerycznych)\n",
    "model = GaussianNB()\n",
    "models.append(model)\n",
    "modelNameList.append(\"GaussianNB\")\n",
    "\n",
    "#Naiwny Bayes traktujący atrybuty jako atrybuty z dyskretnymi wartościami (dobry dla symbolicznych)\n",
    "model = BernoulliNB()\n",
    "models.append(model)\n",
    "modelNameList.append(\"BernoulliNB\")\n",
    "\n",
    "\n",
    "#SVM z jądrem liniowym\n",
    "model = SVC(kernel=\"linear\", C=0.1)\n",
    "models.append(model)\n",
    "modelNameList.append(\"Linear SVM\")\n",
    "\n",
    "#SVM z jądrem wielomianowym\n",
    "model = SVC(kernel=\"poly\",C=0.1, gamma=0.1, degree=3)\n",
    "models.append(model)\n",
    "modelNameList.append(\"Poly SVM\")\n",
    "\n",
    "#SVM z jądrem liniowym\n",
    "model = SVC(kernel=\"rbf\",gamma=1, C=0.1)\n",
    "models.append(model)\n",
    "modelNameList.append(\"RBF SVM\")\n",
    "\n",
    "#Drzewo decyzyjne\n",
    "model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "models.append(model)\n",
    "modelNameList.append(\"DecisionTree\")\n",
    "\n",
    "#Sieć neuronowa (wielowarstwowy perceptron)\n",
    "model =  MLPClassifier(alpha=1, max_iter=1000)\n",
    "models.append(model)\n",
    "modelNameList.append(\"MLPClassifier\")\n",
    "\n",
    "#Tradycyjny model tworzenia klasyfikatora bazujący na rozdzielaniu obiektów z różnych klas za pomocą wielopmianów\n",
    "#stopnia drugiego\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "models.append(model)\n",
    "modelNameList.append(\"QuadraticDiscrim\")\n",
    "\n",
    "#Regresja logistyczna\n",
    "model = LogisticRegression()\n",
    "models.append(model)\n",
    "modelNameList.append(\"LogisticRegression\")\n",
    "\n",
    "#Las losowy\n",
    "model = RandomForestClassifier()  \n",
    "models.append(model)\n",
    "modelNameList.append(\"RandomForest\")\n",
    "\n",
    "#Wzmacniany las losowy\n",
    "model = AdaBoostClassifier() \n",
    "models.append(model)\n",
    "modelNameList.append(\"AdaBoost\")\n",
    "\n",
    "#klasyfikator zepołowy składający sie z rodziny drzew regresji, iteracyjnie ulepszany\n",
    "model = GradientBoostingClassifier()  \n",
    "models.append(model)\n",
    "modelNameList.append(\"GradientBoosting\")\n",
    "\n",
    "#===========================================\n",
    "\n",
    "results = []\n",
    "#Testowanie wszystkich klasyfikatorów\n",
    "for i in range(0,len(models)):\n",
    "    model = models[i]\n",
    "    model.fit(features_train, np.ravel(labels_train))\n",
    "    labels_predicted = model.predict(features_test)\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)    \n",
    "    locList = []; locList.append(accuracy); locList.append(modelNameList[i])\n",
    "    results.append(locList)\n",
    "\n",
    "def myFunc(result):\n",
    "    return result[0]  #Funkcja porównuje według accuracy\n",
    "\n",
    "#Sortowanie wyników\n",
    "results.sort(reverse=True, key=myFunc)\n",
    "\n",
    "#Wypisanie posortowanych wyników\n",
    "for i in range(0,len(results)):\n",
    "    result = results[i]\n",
    "    print(str(i+1)+\".\",result[0],result[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optymalizacja wyczerpująca parametrów tworzenia klasyfikatora\n",
    "\n",
    "Obiekt klasy GridSearchCV pozwala na zastosowanie podejścia brutalnej siły (ang. brute-force) podczas wyboru\n",
    "parametrów modelu tworzenia klasyfikatora. Użytkownik definiuje zbiór możliwych wartości dla\n",
    "co najmniej jednego parametru, a następnie obiekt GridViewCV trenuje model za pomocą\n",
    "każdej kombinacji tych parametrów. Model, który otrzyma najwyższą ocenę wydajności, zostaje\n",
    "wybrany jako najlepszy.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas obliczeń: 0:00:01.812875\n",
      "Najlepsza jakość: 0.725925925925926\n",
      "Parametry najlepszego modelu: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "Konstruktor najlepszego modelu: \n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#Optymalizacja parametrów klasyfikatora k-NN\n",
    "\n",
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv')\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Objaśnienia do miar optymalizacji jakości:\n",
    "#' accuracy' - liczba obiektów dobrze sklasyfikowanych / liczba wszystkich obiektów\n",
    "# 'precision' - liczba obiektów dobrze sklasyf. z danej klasy / liczba wszystkich obiektów sklasyf. do danej klasy \n",
    "# 'recall' - liczba obiektów dobrze sklasyfikowanych z danej klasy / liczba wszystkich obiektów z danej klasy  \n",
    "# 'f1' - 2 * (precision * recall) / (precision + recall) - średnia ważona precision i recall\n",
    "# 'roc_auc' - pole pod krzywą ROC \n",
    "\n",
    "#Parametry do przeszukiwania \n",
    "grid_params = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19], #Różne wartości k\n",
    " 'weights': ['uniform', 'distance'], \n",
    " 'metric': ['minkowski', 'euclidean', 'manhattan'] #Różne rodzaje odległości (metryki)\n",
    "}\n",
    "\n",
    "\n",
    "czasStart = datetime.datetime.now()\n",
    "    \n",
    "gs = GridSearchCV(estimator=knn,\n",
    "                  param_grid=grid_params,                      \n",
    "                  scoring='accuracy',   #'accuracy', 'f1', 'precision', 'recall', '‘roc_auc' \n",
    "                  cv=10,   #Zamiast liczby foldów może być wstawione: LeaveOneOut()                      \n",
    "                  n_jobs=1, #Liczba zadan obliczeniowych (daje przyspieszenie, ale zależy od dostępnego procesora)\n",
    "                  verbose=0 #Bez komunikatów dodatkowych w trakcie obliczeń\n",
    "                 )\n",
    "\n",
    "\n",
    "bestModel = gs.fit(features, np.ravel(labels))\n",
    "\n",
    "czasStop = datetime.datetime.now()\n",
    "roznica = czasStop - czasStart\n",
    "print(\"Czas obliczeń:\", roznica)\n",
    "    \n",
    "print(\"Najlepsza jakość:\",gs.best_score_) \n",
    "print(\"Parametry najlepszego modelu:\",gs.best_params_)\n",
    "print(\"Konstruktor najlepszego modelu: \\n\",gs.best_estimator_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizacja parametrów tworzenia klasyfikatora metodą Monte Carlo\n",
    "\n",
    "Czasami przestrzęń wszystkich możliwych zestawień parametrów klasyfikatora jest zbyt duża i czas ich sprawdzania zbyt długi. Wtedy mozna zastosować obiekt klasy RandomizedSearchCV, który losowo wybiera pewną liczbę zestawień parametrów i tworzy dla nich modele. Model, który otrzyma najwyższą ocenę wydajności, zostaje wybrany jako najlepszy.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas obliczeń: 0:00:00.933104\n",
      "Najlepsza jakość: 0.725925925925926\n",
      "Parametry najlepszego modelu: {'weights': 'uniform', 'n_neighbors': 11, 'metric': 'manhattan'}\n",
      "Konstruktor najlepszego modelu: \n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#Optymalizacja parametrów klasyfikatora k-NN metodą Monte Carlo\n",
    "\n",
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv')\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Objaśnienia do miar optymalizacji jakości:\n",
    "#' accuracy' - liczba obiektów dobrze sklasyfikowanych / liczba wszystkich obiektów\n",
    "# 'precision' - liczba obiektów dobrze sklasyf. z danej klasy / liczba wszystkich obiektów sklasyf. do danej klasy \n",
    "# 'recall' - liczba obiektów dobrze sklasyfikowanych z danej klasy / liczba wszystkich obiektów z danej klasy  \n",
    "# 'f1' - 2 * (precision * recall) / (precision + recall) - średnia ważona precision i recall\n",
    "# 'roc_auc' - pole pod krzywą ROC \n",
    "\n",
    "#Parametry do przeszukiwania \n",
    "grid_params = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19], #Różne wartości k\n",
    " 'weights': ['uniform', 'distance'], \n",
    " 'metric': ['minkowski', 'euclidean', 'manhattan'] #Różne rodzaje odległości (metryki)\n",
    "}\n",
    "\n",
    "\n",
    "czasStart = datetime.datetime.now()\n",
    "    \n",
    "gs = RandomizedSearchCV(estimator=knn,\n",
    "                  param_distributions=grid_params,                      \n",
    "                  scoring='accuracy',   #'accuracy', 'f1', 'precision', 'recall', '‘roc_auc' \n",
    "                  cv=10,   #Zamiast liczby foldów może być wstawione: LeaveOneOut()                      \n",
    "                  n_jobs=1, #Liczba zadan obliczeniowych (daje przyspieszenie, ale zależy od dostępnego procesora)\n",
    "                  verbose=0, #Bez komunikatów dodatkowych w trakcie obliczeń\n",
    "                  n_iter=30\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "bestModel = gs.fit(features, np.ravel(labels))\n",
    "\n",
    "czasStop = datetime.datetime.now()\n",
    "roznica = czasStop - czasStart\n",
    "print(\"Czas obliczeń:\", roznica)\n",
    "    \n",
    "print(\"Najlepsza jakość:\",gs.best_score_) \n",
    "print(\"Parametry najlepszego modelu:\",gs.best_params_)\n",
    "print(\"Konstruktor najlepszego modelu: \\n\",gs.best_estimator_) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
