{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzenie klasyfikatora i testowanie go metodą Train&Test\n",
    "\n",
    "Jedną z najstarszych jak również najważniejszych metod eksploracji danych, która ma bardzo istotne znaczenie praktyczne jest metoda klasyfikacji. Polega ona na znajdowaniu odwzorowania danych w zbiór predefiniowanych klas. Na podstawie zawartości bazy danych budowany jest model (np. drzewo decyzyjne, sieć neuronowa i wiele innych), który służy do klasyfikowania nowych obiektów w bazie danych lub głębszego zrozumienia istniejącego podziału obiektów na predefiniowane klasy. Klasyfikacja jest metodą eksploracji danych z nadzorem (z nauczycielem). Proces klasyfikacji składa się z kilku etapów. Na początku odbywa się budowanie modelu zwanego klasyfikatorem, po czym następuje faza testowania klasyfikatora oraz predykcji nieznanych wartośc\n",
    "i. Danymi wejściowymi w procesie klasyfikacji jest treningowy zbiór obiektów (przykładów, wierszy, obserwacji, próbek), opisanych za pomocą wartości atrybutów warunkowych i wybranego atrybutu decyzyjnego. Wynikiem procesu klasyfikacji jest pewien otrzymany model (klasyfikator), który przydziela każdemu obiektowi testowemu (krotce, przykładowi) wartość atrybutu decyzyjnego w oparciu o wartości atrybutów warunkowych.\n",
    "\n",
    "W pierwszych przykładach konstruujemy klasyfikatory **metodą k-NN**, która mając obiekt testowy u o nieznanej klasie docelowej, najpierw ustala k najbliższych obiektów do u (nazywanych *sąsiadami* u) na podstawie pewnej miary odległości (na przykład euklidesowej). Następnie te k obserwacji „głosuje” na podstawie swojej klasy,\n",
    "a klasa wygrywająca staje się prognozowaną klasą dla u.\n",
    "\n",
    "Pozostałe dwa główne klasyfikatory na tym przedmiocie to klasyfikator oparty na **drzewie decyzyjnym** oraz **naiwy klasyfikator bayesowski** (patrz dalej). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzenie klasyfikatora i testowanie go metodą Train&Test\n",
    "\n",
    "Metoda Train&Test jest naprostrzym podejściem do testowania klasyfikatora i polega na losowy \n",
    "podziale zbioru danych na dwie części z zachowaniem jakiejś proporcji pomiędzy nimi. Pierwsza z tych części\n",
    "nosi nazwę części (tablicy) treningowej, a druga część nosi nazwę części (tablicy) testowej. Proporcja podziału to często 50% na część treningową i 50% na część testową, 60% na część treningową i 40% na część testową lub 70% na część treningową i 30% na część testową. Metoda Train&Test może być stosowana dla danych liczących co najmniej 1000 obiektów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Liczba wierszy= 270\n",
      "Dokładnośc klasyfikacji= 0.5851851851851851\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.90      0.68        67\n",
      "           2       0.73      0.28      0.40        68\n",
      "\n",
      "    accuracy                           0.59       135\n",
      "   macro avg       0.64      0.59      0.54       135\n",
      "weighted avg       0.64      0.59      0.54       135\n",
      "\n",
      "====== MACIERZ POMYŁEK (confusion matrix) =========\n",
      "[[60  7]\n",
      " [49 19]]\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv',',') #Odczytanie zbioru danych\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "noRow = dataset.shape[0] #Ustalenie liczby wierszy w danych\n",
    "print(\"Liczba wierszy=\",noRow)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli parametr nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.5)#, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "#Parametry tworzenia klasyfikatora\n",
    "myNoNeighbors = 20 #Liczba sąsiadów\n",
    "myMetric = 'euclidean' #Rodzaje odległości: 'euclidean', 'manhattan', 'minkowski'\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "model = KNeighborsClassifier(n_neighbors=myNoNeighbors,metric=myMetric) \n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "\n",
    "#Objaśnienia do miar oceny klasyfikatora wypisywanych niżej:\n",
    "# accuracy - dokładność klasyfikacji (liczba obiektów dobrze sklasyfikowanych / liczba wszystkich obiektów)\n",
    "# precision - liczba obiektów dobrze sklasyf. z danej klasy / liczba wszystkich obiektów sklasyf. do danej klasy \n",
    "# recall - liczba obiektów dobrze sklasyfikowanych z danej klasy / liczba wszystkich obiektów z danej klasy  \n",
    "# f1-score - średnia ważona precision i recall obliczana według wzoru: f1' - 2 * (precision * recall) / (precision + recall)\n",
    "# support - liczba obiektów należących do danej klasy decyzyjnej\n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n",
    "print(\"====== MACIERZ POMYŁEK (confusion matrix) =========\")\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dane/serce.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8ab4e745247b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dane/serce.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Odczytanie zbioru danych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnoColumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dane/serce.csv'"
     ]
    }
   ],
   "source": [
    "#To co wyżej, ale z wizualizacją macierzy pomyłek\n",
    "\n",
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "print(\"noColumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.2, random_state=1234)\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "\n",
    "decValues = labels_test['diagnoza'].value_counts()\n",
    "print(\"Wartosci atrybutu decyzyjnego w tablicy testowej:\")\n",
    "print(decValues)\n",
    "\n",
    "#Parametry tworzenia klasyfikatora\n",
    "myNoNeighbors = 5 #Liczba sąsiadów\n",
    "myMetric = 'euclidean' #Rodaje odległości: 'minkowski', 'euclidean', 'manhattan'\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "model = KNeighborsClassifier(n_neighbors=myNoNeighbors,metric=myMetric) \n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test)\n",
    "\n",
    "\n",
    "#Pozyskiwanie wartości decyzji\n",
    "class_names_ordered = sorted(np.unique(labels_train))\n",
    "my_class_names = []\n",
    "for i in range(0,len(class_names_ordered)):\n",
    "    my_class_names.append(str(class_names_ordered[i]))\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n",
    "\n",
    "dataframe = pd.DataFrame(conf_matrix, index=my_class_names, columns=my_class_names)\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, annot_kws={\"size\": 16}, cmap=\"Blues\")\n",
    "plt.title(\"Macierz pomyłek\"), \n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Klasy prawdziwe\"), \n",
    "plt.xlabel(\"Klasy prognozowane\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Zad 1. Napisz program który odczytuje tablicę danych rezygnacje.csv oraz wybiera z niej wszystkie wiersze oraz\n",
    "#kolumny: CZAS_POSIADANIA, PLAN_MIEDZY, POCZTA_G, L_WIAD_POCZTA_G, L_POL_BIURO, REZYGN. \n",
    "#Następnie wykonuje szereg eksperymentów z tworzeniem klasyfikatorów i testowaniem ich metodą Train&Test, przy czym \n",
    "#jest to zawsze klasyfikator k-NN (te same parametry tworzenia) występujący w powyższych 2 przykładach przy \n",
    "#atrybucie decyzyjnym 'REZYGN'. Eksperymenty są wykonywane przy następującyh wielkościach tablicy \n",
    "#treningowej: 90%, 80%, 70%, 60%, 50%, 40%, 30%, 20% i 10%. \n",
    "#Oczywiście, jeśli np. tablica treningowa liczy 70% całych danych, to tablica testowa liczy 100% - 70% = 30%.\n",
    "#Wykonać wykres porównujący jakości klasyfikacji (accuracy) dla wszystkich eksperymemntów i wyciągnąć wniosek \n",
    "#czy i jak proporcja podziału danych ma wpływ na jakośc klasyfikacji. Odpowiedni wniosek zapisać słownie \n",
    "#w komentarzu na końcu komórki z rozwiązaniem.\n",
    "\n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "\n",
    "def test(testSize):\n",
    "    dataset = pd.read_csv('./rezygnacje.csv', usecols=['CZAS_POSIADANIA', 'PLAN_MIEDZY', 'POCZTA_G', 'L_WIAD_POCZTA_G', 'L_POL_BIURO', 'REZYGN'])  # Odczytanie zbioru danych\n",
    "\n",
    "    features = dataset.iloc[:, :-1]\n",
    "    labels = dataset.iloc[:,-1]\n",
    "\n",
    "    datasets = train_test_split(features, labels, test_size=testSize, random_state=1234)\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\n",
    "    #Parametry tworzenia klasyfikatora\n",
    "    myNoNeighbors = 5 #Liczba sąsiadów\n",
    "    myMetric = 'euclidean' #Rodaje odległości: 'minkowski', 'euclidean', 'manhattan'\n",
    "\n",
    "    #Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "    model = KNeighborsClassifier(n_neighbors=myNoNeighbors,metric=myMetric) \n",
    "    model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "    labels_predicted = model.predict(features_test)\n",
    "\n",
    "    accuracy = accuracy_score(labels_test, labels_predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "x = np.arange(90, 0, -10)\n",
    "y = np.array([test(testSize) for testSize in x])\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#Najwyzsza dokladnosc uzyskujemy dla 60% tablicy treningowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testowanie klasyfikatora metodą  cross-validation\n",
    "\n",
    "Innym sposobem testowania klasyfikatora, szczególnie przydatnym jeśli sformułowaniu problemu klasyfikacyjnego nie towarzyszy naturalny podział na próbki treningowe i testowe, jest walidacja krzyżowa (ang. cross-validation). Przy danym parametrze n (który na ogół ustawiany jest jako 5 lub 10), dzielimy dane losowo na n równych podzbiorów. Czasem też zakłada się, iż rozkłady występowania poszczególnych klas decyzyjnych w poszczególnych podzbiorach są zbliżone do siebie. Następnie, w pętli, każdy z kolejnych n podzbiorów przyjmuje się jako testowy, zaś pozostałe podzbiory tworzą próbkę treningową. W ten sposób wykonujemy n eksperymentów i każdy eksperyment dostarcza wyniku klasyfikacji. Wyniki te na końcu uśredniamy. Możemy także wyliczyć odchylenie standardowe tych wyników. Zauważmy, że choć metoda ta jest bardziej kosztowna obliczeniowo, z powodu powtarzania fazy treningu i testowania klasyfikatora n razy, to uśrednione wyniki jakości stają sie bardziej stabilne i wiarygodne. Dzieje się tak dlatego, że wymienne traktowanie danych jako składowych treningowych i testowych obniża ryzyko otrzymania wyniku niezgodnego z rzeczywistością, spowodowanego niefortunnym losowym podziałem danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładnośc klasyfikacji (accuracy) dla części: [0.62962963 0.7037037  0.66666667 0.74074074 0.59259259 0.7037037\n",
      " 0.62962963 0.51851852 0.77777778 0.66666667]\n",
      "Średnia dokładność: 0.662962962962963\n",
      "Odchylenie standardowe: 0.071145824860365\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5,metric='euclidean') \n",
    "\n",
    "\n",
    "noFold = 10 #Liczba tzw. foldów (podziałów w teście CV)\n",
    "\n",
    "scores = cross_val_score(model, features, np.ravel(labels), cv=noFold\n",
    "                        )\n",
    "print(\"Dokładnośc klasyfikacji (accuracy) dla części:\",scores)\n",
    "print(\"Średnia dokładność:\",scores.mean())\n",
    "print(\"Odchylenie standardowe:\", scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9uUlEQVR4nO3deXxV9Z34/9c7GyEJSUgCAZJAICCLLIGELbRVUKdoF0UFper47WitVTu201p1Op2Zzvy62mW6WJ2OOnSqhQYRF2rFpbjUgJIAIghIEpaEPQuBJGS9798f98ZeQ0Jukpucu7yfj8d9JOeczzn3fW9yz/uez+dzPh9RVYwxxoSfCKcDMMYY4wxLAMYYE6YsARhjTJiyBGCMMWHKEoAxxoSpKKcD6I20tDTNzs7u074NDQ3Ex8f7NyA/sLh6x+LqHYurdwI1LuhfbCUlJVWqOuK8DaoaNI+8vDztq02bNvV534FkcfWOxdU7FlfvBGpcqv2LDSjWLs6pVgVkjDFhyhKAMcaEKUsAxhgTpiwBGGNMmLIEYIwxYcqnBCAiS0Vkn4iUisgDXWy/T0R2eB67RKRdRFJEJEtENonIHhHZLSL3eu2TKyJbPPsUi8g8f74wY4wxF9ZjAhCRSOBh4EpgGrBSRKZ5l1HVh1Q1V1VzgQeBN1S1BmgDvqGqU4EFwN1e+/4Y+K5nn3/1LBtjjBkkvlwBzANKVbVcVVuANcDVFyi/ElgNoKrHVHWb5/ezwB4gw1NOgUTP70nA0d6Hb4zpzpmmVt6oaMXlsiHfTddEe5gPQESuB5aq6u2e5VuA+ap6Txdl44BKYKLnCsB7WzbwJjBdVc+IyFRgIyC4E1GBqh7q4ph3AHcApKen561Zs6bXLxKgvr6ehISEPu07kCyu3rG4fPfM/haeL2vla3OGkDsysG76D8T3CwI3LuhfbIsXLy5R1fzzNnR1d5j3A1gOPOa1fAvwq27K3gC80MX6BKAEuNZr3S+B6zy/rwBe7SkWuxN48FhcvRNocbW1u3Th91/Vcfdv0Dv+b6vT4Zwn0N6vDoEal6pzdwJXAlley5l0X11zI57qnw4iEg2sA55S1We8Nt0KdCyvxV3VZIzxg6KyKo7WNTEmXnhtz0mq65udDskEIF8SwFZgkoiMF5EY3Cf55zsXEpEk4BLgOa91AjwO7FHVn3Xa5ainPMASYH/vwzfGdKWwuJLkuGi+PGsIbS5l/fYjTodkAlCPCUBV24B7cNfX7wEKVXW3iNwpInd6FV0GvKyqDV7rFuGuMlri1U30Ks+2LwE/FZH3gO/jqec3xvTP6cYWNu4+zjW5GYxLjGRWVjKFxRUdVa/GfMSnliFVfRF4sdO6RzstrwJWdVr3V9yNvF0d869Anu+hGmN88fx7R2lpc7E8P5NTH55iRX4m316/i52VdczKSnY6PBNA7E5gY0JMYXEFF49J5OIxSQB8btYYhkRFUFhc4XBkJtBYAjAmhOw+WseuI2dYkf+3fhuJsdFcNWM0z+84yrmWdgejM4HGEoAxIWRtcSUxkRFcnTvmY+uX52dytrmNjbuPOxSZCUSWAIwJEc1t7Ty34wh/d3E6yXExH9u2YHwqWSlDWVti1UDmbywBGBMiXttzktrGVpbnZ523LSJCWJ6Xxdul1VTUNDoQnQlElgCMCRGFxRWMTorlExPTutx+XV4mIvB0SeUgR2YClSUAY0LAsbpzvPnhKa7PyyQyosue12QkD+UTE9N4uqTSBogzgCUAY0LCM9uO4FK4Pi/zguWW52dx5PQ5isqqBykyE8gsARgT5FSVwuIKFkxIYVxq/AXL/t20dBJjo+yeAANYAjAm6L17oIZD1Y0f6/vfndjoSK6ZncFLu49T19g6CNGZQGYJwJggt7akkoQhUVw5fbRP5VfkZ9HS5uL5nTYHU7gLiwTw2Fvl/FdJk9NhGON39c1t/GnnMT43azRDYyJ92ufiMYlMHZ3IWqsGCnthkQCaWtvZcaqdmoYWp0Mxxq/+tPMo51rbu+z73x0RYXleJjsr69hz7MwARmcCXVgkgAJPv+jN1vPBhJjC4komjkxgdi9H+bxmdgbRkcLaYrsnIJyFRQKYmZFEbKR7liRjQkXpyXpKDtWyIj8T99xLvkuJj+GKaems315JS5trgCI0gS4sEkBUZASTUyLtCsCElLUlFURGCMtmX7jvf3eW52dR29jKa3tO+DkyEyx8SgAislRE9olIqYg80MX2+7xm/NolIu0ikiIiWSKySUT2iMhuEbm3035f9Rx3t4j82F8vqitTUyIpr2rgWN25gXwaYwZFW7uLZ7YdYcmUkYwYNqRPx/jUpBGMSoy1ewLCWI8JQEQigYeBK4FpwEoRmeZdRlUfUtVcVc0FHgTeUNUaoA34hqpOBRYAd3fsKyKLgauBmap6MfAT/72s801Ndb9UuwowoeCND09x6myzT33/uxMZIVyXl8EbH57ixBnrJReOfLkCmAeUqmq5qrYAa3CfuLuzElgNoKrHVHWb5/ezuOcUzvCU+wrwQ1Vt9mw/2beX4JusYREMj4u2W+BNSCgsriAtIYZLJ4/o13GW52XhUli3zRqDw5H0NFG0iFwPLFXV2z3LtwDzVfWeLsrGAZXARM8VgPe2bOBNYLqqnhGRHcBzwFKgCfimqm7t4ph34JkwPj09PW/NmjW9fY0A1NfXs2p/FOV1Ln56ydBeN5oNlPr6ehISEpwO4zwWV+8MZlxnmpWvv97IFeOiuXFKzAXL+hLX9985R12z8sNPDt7nwv6Ovdef2BYvXlyiqvnnbVDVCz6A5cBjXsu3AL/qpuwNwAtdrE8ASoBrvdbtAn6Je9L4ecABPAmpu0deXp721aZNm/T/Nh/Ucfdv0AOn6vt8HH/btGmT0yF0yeLqncGM63/eLNNx92/QD4+f6bGsL3EVbj2s4+7foO8eqPZDdL6xv2Pv9Sc2oFi7OKf6UgVUCXhXNGYC3d1DfiOe6p8OIhINrAOeUtVnOh33GU987wIuoOuBzP2kICcVwKqBTNBSVf64tYLZY5OZlD7ML8e8asZo4mMiKdxqjcHhxpcEsBWYJCLjRSQG90n++c6FRCQJuAR3tU7HOgEeB/ao6s867fIssMRT7iIgBhjQjvoT0uJJTxxi9wOYoPVeZR37T9b3q/G3s/ghUXx25hj+9P4x6pvb/HZcE/h6TACq2gbcA2zE3YhbqKq7ReROEbnTq+gy4GVVbfBatwh3ldESr26iV3m2PQFMEJFduBuWb/VcqgwYEaEgJ43NZdUM8FMZMyDWFlcQGx3BZ2f6NvCbr1bMzaSxpZ0Xdx7z63FNYIvypZCqvgi82Gndo52WVwGrOq37K+46/q6O2QLc7Huo/rEwJ5X124/w4Yl6Jo/yzyW0MYPhXEs7z+84ylXTRzMsNtqvx54zdjgTRsSztqSCFXP9d3VhAltY3AnsraMd4O1SqwYywWXj7uOcbW7r1cBvvhIRVuRnsfVgLeWn6v1+fBOYwi4BZA6PY1xqnDUEm6BTWFzB2JQ45o9PGZDjXzs7g8gIYa1NGh82wi4BgPsq4J3yatrabRAsExwqahopKqtmeV4mEd1M+t5fIxNjufSiEawrqbTPRpgIywSwMCeNs81t7D5qY6Gb4LC2pBIRuK6HSd/7a3l+FifPNvPm/lMD+jwmMIRnAphg9wOY4OFyKetKKvnkpBGMSR46oM+1ZMpIUuNjKNxq1UDhICwTwIhhQ7goPcHuBzBBoaismiOnz7Eif2C//QPEREWwbHYGr+45QXV984A/n3FWWCYAgIKcNLYerKG5rd3pUIy5oMLiCpKGRnP51PRBeb7l+Vm0uZRnd9ik8aEujBNAKk2tLnYcPu10KMZ0q66xlZd2H+ea3DHERvs26Xt/TR41jFlZyawtrrAbJkNc2CaA+RNSiRBrBzCB7fn3jtDS5hqQvv8Xsjwvk73Hz/L+kbpBfV4zuMI2ASQNjWZ6RpJNEGMCWmFxJdNGJzI9I2lQn/dzs8YwJCrCZgsLcWGbAMA9LMT2iloaW2wALBN49hw7w/tH6gal8bezpKHRXDl9FM/tOEpTq7WThaqwTgAFOWm0tivFB2udDsWY86wtriQmMoKrczN6LjwAVuRncbapjY27jzvy/GbghXUCmJs9nOhI4W3rDmoCTEubi/XbK7liWjrD4y8869dAWTAhlczhQ1lbbPcEhKqwTgBxMVHMzhpu7QAm4Ly25wS1ja0sd6D6p0NEhLA8L4u3y6qoqGl0LA4zcMI6AYC7HWDXkTrqGludDsWYjxQWVzAqMZZPTurfpO/9dV2eu/rJJo0PTWGfAApyUnEpvHPArgJMYDhe18QbH57i+rxMIgdo4DdfZQ6PY1FOGmuLK3G57J6AUONTAhCRpSKyT0RKReSBLrbf5zXj1y4RaReRFBHJEpFNIrJHRHaLyL1d7PtNEVERGdD5gLuTOzaZ2OgIux/ABIx12ypxKVw/wAO/+Wp5fiZHTp9jc7l9RkJNjwlARCKBh4ErgWnAShGZ5l1GVR9S1VxVzQUeBN5Q1RqgDfiGqk4FFgB3e+8rIlnAFcBhP72eXhsSFcnc7BRrBzABQVV5uqSS+eNTyE6LdzocAD598SgSY6PsnoAQ5MsVwDygVFXLPdM4rgGuvkD5lcBqAFU9pqrbPL+fxT2nsHeftp8D3wIcvbYsyElj34mznDprg18FsqbWdirOhvY49cWHajlQ1eDXSd/7KzY6kqtzM3hp13HqzllbWSjxZU7gDMA79VcC87sqKCJxwFLck8h33pYNzAbe8Sx/Hjiiqu+JdF/PKSJ3AHcApKen8/rrr/sQ8vnq6+u73XdInftGl8c3vMWC0T5Nk+w3F4rLSYEY14ayFp7e30rVuVeZPXJw/0498df79fj7zcRGQkLtfl5/vTRg4sqRdprbXPx07essGdv/+YgD8f8LAjcuGKDYVPWCD2A58JjX8i3Ar7opewPwQhfrE4AS4FrPchzuRJDkWT4IpPUUS15envbVpk2but3W2tau0//tJX1g3Xt9Pn5fXSguJwViXDf8d5GOu3+Dzvi3l/RQVYPT4XyMP96vs02tOvU7f9b7n/bf/6G//o4ul0s//fM39PO/essvxwvE/y/VwI1LtX+xAcXaxTnVlyqgSsD7ejQT6G6c2BvxVP90EJFoYB3wlKo+41mdA4wH3hORg55jbhORUT7E43dRkRHMH59qDcEBrKm1nW2HTpOfHomI8JWnSkJuiIIXdx6jsaV90Ad+80XHpPHvVdax97jNpBcqfEkAW4FJIjJeRGJwn+Sf71xIRJKAS4DnvNYJ8DiwR1V/1rFeVd9X1ZGqmq2q2biTzBxVdeye84KcVA5VN1JZaze8BKKSQ7W0tLv4ZGYUP79hFruPnuHfn9/tdFh+VVhcQc6IeOaMTXY6lC5dMzuD6EixO4NDSI8JQFXbcNfpb8TdiFuoqrtF5E4RudOr6DLgZVVt8Fq3CHeV0RKvbqJX+TF+vymY6J4m0noDBaaisioiI4SLhkeyZEo69yyeyJqtFSHTM6XsVD3Fh2pZkZ/FhdrEnJQSH8PlU9NZv909RLUJfj61pKnqi8CLndY92ml5FbCq07q/Aj3+N3uuAhw1OX0YqfExbC6rDshL8HBXVFbNrMwkhka5e6F8/YqL2F5Ry3ee3cXFYxK5eMzgDpfsb0+XVBIZISyb48zAb75akZ/Fn3cd5y97T7B0+minwzH9FPZ3AncQERbmpPJ2WZXNghRgzja1srOyjoKcv90rGBkh/OLG2QyPi+Gup7YFdffEtnYX60oqWTx5BCOHxTodzgV9clIa6YlDKLRqoJBgCcBLQU4aJ840U17V0HNhM2i2Hqyh3aUU5KR+bH1awhAevmkOR2rP8c217wVt4n5z/ylOnm0OiivPqMgIrpuTyev7TnLiTJPT4Zh+sgTgpeMEY72BAktRaTUxURHMGTf8vG1544bzz1dN5ZUPTvDfb5Y7EF3/FW6tJC0hhiVTRjodik+W52fhUnhm2xGnQzH9ZAnAy7jUOMYkxbLZ5gcIKEVl1eSNHd7tpOhfXJTNZ2aO5scv7Q26Rvzq+mZe3XOCZbMziI4Mjo/j+LR45mWn2KTxISA4/uMGibsdII3NZdU28mGAqG1o4YNjZ86r/vEmIvzoupmMT4vnq6u3B1XVxPrtR2hzaVBU/3i7Pj+T8qoGSg7ZbHrBzBJAJ4smplLb2Mre42edDsUAWzwjUHZ00+1OwpAoHr05j8aWNu75wzZa2wO/m6Kqsra4ktysZC5KH+Z0OL3ymRmjiYuJDJluuOHKEkAnCz9qB7BqoEBQVFZNXEwkMzOTeyw7KX0YP7h2BlsP1vLjl/YOfHD99P6ROvadOBtQA7/5Kn5IFJ+dOZoNO4/R0NzmdDimjywBdDI6aSgT0uKtIThAFJVVMW98is/141fnZnDrwnH8z1sH+PP7xwY4uv4pLK4gNjqCz84Kzv70K/KzaGxp508B/j6b7lkC6MLCnFTeKa8OimqEUHbiTBNlpxouWP/flW9/Zhq5Wcnc9/ROyk/VD1B0/dPU2s5zO45y5fTRJMb2f3RNJ+SNG86EtHietnsCgpYlgC4U5KTR0NLO+0fqnA4lrHX06PG+AcwXMVERPHzTHKIjha88uY3GlsCroti4+zhnm9ocnfS9v0SE5flZvHuwJmATrbkwSwBdWDAhBbBxgZxWVFZF0tBopo5O7PW+GclD+cWNs/nw5Fn+Zf2ugOuuWFhcQVbKUBaM793VTaC5bk4GkRHC0yV2FRCMLAF0ITVhCFNHJ1pDsMOKyqpZMCGlzxOjf+qiEXztsot4ZvsR/vCuY7OOnqeippG3S6tZnpdFhMOTvvfXyMRYLrloBOu2VdJmVaZBxxJANwpyUik+WBtyY84Hi4qaRiprz7FoYu+qfzr76pKJXDp5BN99/gN2Vp72T3D9tG5bJSJwXYBM+t5fK/IzOXGmmbf22xemYGMJoBsFOak0t7nYdthudHFCx9VXbxuAO4uIEH6+IpcRw4bwlSe3UdvQ4o/w+szlcvf9/8TENDKShzoai78smZJOSnyM3RMQhCwBdGPeeHfVg7UDOKOorJoRw4aQMyKh38caHh/Db26aw6mzzXy9cIejd3lvLq/myOlzQXfn74XEREWwbHYGr+45QY3DCdb0jiWAbgyLjWZGRpLdD+AAVaWorJqCnFS/TY4yKyuZf/3cNF7fd4pfb+r/ZOt9VVhcQWJsFH83Ld2xGAbCivwsWtuVZ7fbAHHBxKcEICJLRWSfiJSKyANdbL/Pa8avXSLSLiIpIpIlIptEZI+I7BaRe732eUhE9orIThFZLyLJfnxdflGQk8p7FaeptzsdB1XZqXpOnW3ud/VPZzfNH8uy2Rn8/NUPeWv/Kb8e2xd1ja38eddxrpmd0e3AdsFq8qhhzMpMotAGiAsqPSYAEYkEHgauBKYBK0VkmncZVX1IVXNVNRd4EHhDVWuANuAbqjoVWADc7bXvK8B0VZ0JfOjZL6AU5KTR5lK2HqxxOpSwUtTH/v89ERG+t2w6F40cxj+u3s7R0+f8evyePL/zKC1trqAc+sEXy/Oz2Hv8LLuO2KTxwcKXK4B5QKmqlqtqC7AGuPoC5VcCqwFU9ZiqbvP8fhb3nMIZnuWXPfMNA2wBAq5LRH72cGIiIygqtd4Ng6motJrM4UPJSonz+7HjYqJ45OY5tLYrdz21bVDntl1bXMHU0YlcPKb39zUEg8/NGsOQqAhrDA4i0tPlmohcDyxV1ds9y7cA81X1ni7KxgGVwETPFYD3tmzgTdzf+s902vYC8EdVfbKLY94B3AGQnp6et2bNGt9fnZf6+noSEnrfoPjDd89xrg2+WzAwPTb6GtdAcyoulypf/Usjc0ZGcduMIQMW19bjbTy8o5nLxkZxy7Tzn6e3eoqr4qyL77x9jpumxHBF9uAN/TDYf8dH32ti56l2/mtxHDGR3bff2P997/UntsWLF5eoav55G1T1gg9gOfCY1/ItwK+6KXsD8EIX6xOAEuDaLrZ9G1iPJxld6JGXl6d9tWnTpj7t94tXP9TsBzZoTX1zn5/7Qvoa10BzKq73K0/ruPs36PptlV1u92dc//nCbh13/wZ9dnvXz9UbPcX1Hy/s1on//CetHqD/o+4M9t/xr/tP+fSe2v997/UnNqBYuzin+lIFVAl4V1pmAke7KXsjnuqfDiISDawDnlLVZzptuxX4LHCTJ8iAU5CTiiq8c8B6Aw2Gjv7/C/3cANyV+6+cwtzs4Tyw7n32nxi4+R9a2lys336EK6a5+8uHsoUTUslIHmpDQwQJXxLAVmCSiIwXkRjcJ/nnOxcSkSTgEuA5r3UCPA7sUdWfdSq/FLgf+LyqNvb9JQysmZnJxMVEWnfQQVJUVk3OiHjSE2MH/LmiIyP49RfmED8kijufLBmw3l5/2evuHx9Kff+7ExEhLM/P5K+lVVTWBuzH2nj0mADU3VB7D7ARdyNuoaruFpE7ReROr6LLgJdVtcFr3SLcVUZLvLqJXuXZ9mtgGPCKZ/2j/nhB/hYTFcHc7BRLAIOgtd3Fuwdq/N7750LSE2P51crZHKhq4P51OwekC2NhcSWjEmP51KQRfj92ILreM8TFuhK7JyDQRflSSFVfBF7stO7RTsurgFWd1v0V6LIlSFUn9iJORy2amMr3X9zLiTNNg/LNNFztrDxNY0u73/v/92RhTir3fXoKP3ppL/njhvPFReP9duwTZ5p4fd9JvnJpTp8HtQs2mcPjWJSTxtqSCr66ZGLQD3gXyuxOYB90fCO1YSEGVlGp+/1dMGHwh0i+85IJXD41ne/9aY9fJzp/ZtsRXArL80K/+sfb8vxMKmvPfTSnswlMlgB8MHV0IklDo2146AFWVFbNtNGJDHegoVRE+OmKWYxJHsrdT22jqr6538dUVdYWVzBvfArZafF+iDJ4fPriUQyLjbJ7Avzg5Jkmvvz7Yk43+f+eFUsAPoiMEBZMsHaAgdTU2k7J4dpBr/7xljQ0mkdunkNtYwv3rtlOez8HjSs5VEt5VQPLQ2TY596IjY7k6twx/HnXcerOtTodTtD64OgZrnn4bd7aX8XRBv+3T1kC8FFBThqVteeoqLGeDQNh26FaWtpcFEx0doasi8ck8Z/XTOft0mp+/sqH/TpWYXEF8TGRXDUjOCd9768V+Vk0t7nYsLO7XuPmQv6y9wTLHy3CpbD2zoVMS/X/+FGWAHzU8c3UqoEGRlFZNZERwtzsFKdDYUV+FjfkZ/HrTaX8Ze+JPh2jobmNDTuP8dmZY4gf4lNfi5AzIyOJKaOGUWiTxveKqvK/bx/g9t8VM35EPM/ds4iLxyQNyHNZAvDRxJEJjBg2hLdLrRpoIBSVVTEzM4lhsYM3TMKFfPfqi7l4TCJfW7OjT1d9f3r/GI0t7ayYG37VPx06Jo1/r+I0+44P3I12oaSt3cW/Preb777wAZdPTafwywsHtOehJQAfiQgFOakUlVXbcLd+Vt/cxnuVdY7W/3cWGx3JIzflAfCVp0p6PTXo2uIKJoyIZ87Y4QMRXtC4JncM0ZHCWmsM7tHZplZu+10xv99yiC9/agKP3pxHXMzAXj1aAuiFgpxUquqbKT1Z73QoIWXrgRraXTqoN4D5YmxqHD9bkcuuI2f47gsf+Lxf+al6th6sZUV+lt8mtAlWqQlDuGxKOuu3HxnUkVeDTWVtI9c/spm3S6v4wbUzePCqqYNy/4QlgF7oOEFZbyD/KiqrIiYqgrxxgfdt+fJp6dx1aQ6r3z3s8/g2T5dUEhkhXDs7Y4CjCw4r5mZS3dDCX/aedDqUgLT9cC3XPPw2R+vO8bt/mMfKeWMH7bktAfRCVkocmcOHWkOwnxWVVZM3dnjAzpL1T1dcxMIJqXx7/ft8cPTCk520tbtYt62SSy8awUi7axyAT00awchhQ6waqAsbdh7lxt9uIS4mivV3FbBo4uBeBVsC6KWCnFS2lNf0u4+4cattaOGDY2cCqv6/s6jICH65cjbJcdHc9VQJZ5q679f+1v4qTpxpDouB33wVFRnBdXmZvP7hKU6eaXI6nICgqjy8qZR7/rCdGRlJrL+rgIkjhw16HJYAemnRxDTqzrX2+E3Q+OadA9Wo4nj//56MGDaEh78wh8rac3yz8L1uOwIUFleQGh/DkikjBznCwLY8L5N2l/KMTRpPc1s731y7k4c27uOa3DE8eft8UhP6PylRX1gC6KWFE+x+AH8qKqsmLiaSmZnJTofSo/zsFB68aiovf3CC375Zft72moYWXt1zgmWzM4iJso+WtwkjEpibPTzsJ42vbWjhlsffZd22Sr5++UX8/IZcR6s+7b+0l0YmxjJxZII1BPtJUVk188anEB0ZHP+K/7Aom8/MGM2PN+47b6CzZ7cfobVdrfqnG8vzsyg/1cC2w/4bbC+YlJ2qZ9lv3mZHxWl+cWMu914+yfFeYsHxqQswBTmpbD1YY93a+unkmSZKT9YHdP1/ZyLCD6+bwbiUOO75w/aP6rRVlcLiCmZlJTN51ODX5QaDz8wYTVxMJIVbw+/O4M1l1Vz7myLONrWx+kvzuTo3MHqIWQLog4KcVBpb2tlZedrpUILaZs836EDr/9+TYbHRPHJzHg3Nbdyzejtt7S4OnXGx9/jZsBz4zVfxQ6L4zIzRbNh5lKa28KkGKiyu4JbH32HEsCE8e/ci8sY5P9xJB58SgIgsFZF9IlIqIg90sf0+rxm/dolIu4ikiEiWiGwSkT0isltE7vXaJ0VEXhGR/Z6fgdcJvBsLJqQiYvcD9FdRaTVJQ6OZOjrR6VB6bfKoYfzg2hm8e6CGhzbu480jbQyJiuBzs8Y4HVpAWzE3i4aWdrYeH5jpNwOJy6X86KW9fOvpnSzMSWXdVwrISolzOqyP6TEBiEgk8DBwJTANWCki07zLqOpDqpqrqrnAg8AbqloDtAHfUNWpwALgbq99HwBeU9VJwGue5aCQHBfDxWMSebvUGoL7o6i8igUTUoJ2pqxrZmdwy4Jx/Peb5bxV2caV00eRNDQwxjIKVPnjhjM+LZ6/HgntBHCupZ27/7CNR14v4wvzx/LE/5sbkP8bvlwBzANKVbVcVVuANcDVFyi/ElgNoKrHVHWb5/ezuOcU7qj8uhr4nef33wHX9Dp6BxXkpLH98GnOtfRujBjjVlHTSEXNuaCr/unsXz47lVlZybS63KOImgtzDxCXyb5aFw8+s5PdR+ucDsnvTp5p4sbfbual3cf5l89M5XvXTA/YTg7SU5csEbkeWKqqt3uWbwHmq+o9XZSNAyqBiZ4rAO9t2cCbwHRVPSMip1U12Wt7raqeVw0kIncAdwCkp6fnrVmzpnev0KO+vp6EhIQ+7duVnafa+FlJM/flx3JxWt+7cfk7Ln8Z6LjeqGzlf3e18L1PDCUjwfcPRyC+X6ebXWw70sji8fGO9+roLBDfr6Y25XfvN1B8Smh1wcTkCBZnRTF3VBQxkc6+f/19vyrOuvh5SRP1rcpXZg1h9kj/DebWn9gWL15coqr5521Q1Qs+gOXAY17LtwC/6qbsDcALXaxPAEqAa73Wne5UpranWPLy8rSvNm3a1Od9u3K2qVVzHvyT/ujPe/p1HH/H5S8DHdc/rt6mef/5irpcrl7tF67vV18FclynG1r0sbfK9dKHNum4+zdo7nc36vdf/EAPVTU4Gldf/WXPCZ32nT/rvO+9ou9XnvZfUB79iQ0o1i7Oqb6kp0rA+9o2E+huip8b8VT/dBCRaGAd8JSqPuO16YSIjFbVYyIyGgiqkaIShkQxKyvZGoL7QFUpKqumICc14L4xm8GTFBfNbZ8YzxcLsikqq+bJLYd47K0D/PbNci65aAS3LBjHpZNHBkUb0aq3D/AfGz5g6uhEHr91LqOSgmMcKF8SwFZgkoiMB47gPsl/oXMhEUkCLgFu9lonwOPAHlX9WaddngduBX7o+flcX16AkwpyUnl4UylnmlpJDJCJTIJB2al6Tp1tDqr+/2bgREQIn5iUxicmpXGs7hyr361gzbuHue13xWQkD+UL88dyw9ws0hwaLuFC2tpd/MeGD/i/zYe4fGo6v7gxN6hmgOux8lVV24B7gI24G3ELVXW3iNwpInd6FV0GvKyqDV7rFuGuMlri1U30Ks+2HwJXiMh+4ArPclApyEnDpfBueU3Phc1HOq6agr0B2Pjf6KSh/NMVF/H2A0v4zU1zGJsSx0Mb97HwB6/xj6u3s/VgTcAMJdExgcv/bT7Elz45nv++JS+oTv7g2xUAqvoi8GKndY92Wl4FrOq07q9Al9dvqloNXOZ7qIFn9thkhkRFUFRWzeXT0p0OJ2gUlVaTkTyUrJShTodiAlR0ZARXzRjNVTNGU3ryLE9uOcy6kkqef+8oU0YN46YF41g2O4MEh064lbWN3LaqmNJT9Xx/2Qy+MH/wxvD3p8DsmxQkYqMjyc8ebgPD9YLLpWwut/p/47uJI4fx75+/mHe+fRk/vHYGkRHCd57dxfzvvcp3nt016PMNuydwKeJo3TlWfXFu0J78wccrANO9gpw0Htq4j+r6ZseGdA0mHxw7Q9251oAf/tkEnriYKG6c524P2FFxmt9vOcQfiyv4/ZZDzMtO4aYFY7ly+ugBHYn1TzuP8U+FOxiZOIQ1d8x3ZAx/f7IrgH5a6GnI3GLtAD7Z7Kn/XzjB6v9N34gIs8cO52crctny4GU8eOUUjp9p4t41Oyj44Ws8tHEvlbWNfn1O9UzgcvcftjE9I4ln71oU9Cd/sCuAfpuZkUTCkCiKyqr4zMzRTocT8IrKqpgwIj5ousmZwJYSH8OXL8nhS5+cwJv7T/HklsM88noZj7xexpIpI7l5wTg+NWlEvyZYb2lz8eAz77NuWyVX547hR9fNDNjpS3vLEkA/RUVGMH98it0P4IPWdhfvHqhh2ZzAGArXhI6ICOHSySO5dPJIKmsbWf3uYf64tYJX95xkbEocN80fy/L8LFLiY3p13NqGFr78ZAnvHqjha5dP4t7LnB/D35+sCsgPFuakcqCqgaOnzzkdSkDbWVlHQ0u7df80AypzeBz3fXoKRQ9cxi9XzmZUYiw/+PNeFvzgNf7pjzvYdrjWp66k5R0TuBw+zX/dkMvXLr8opE7+YFcAftFxQttcVs11Nh58tzZ7ekt1TKtpzECKiYrg87PG8PlZY9h3/CxPbjnE+u1HeGb7ES4ek8jNC8Zxde4Y4mLOPw1uLqvmzidLiIwQ/vCl+eRnB84Y/v5kVwB+MGXUMIbHRVs1UA+KyqqZNjqR4b28DDemvyaPGsZ/XjOdLf98Gf/fNdNpdykPPvM+87//Gv/+/G5KT/6tK2lhcQV//8Q7pCXE8Oxdi0L25A92BeAXERHCwpxUNpdVoaohd5noD02t7RQfquXvF4xzOhQTxhKGRHHzgnHcNH8sxYdqeXLLIZ565xCrig6ycEIqMS3NvFG5k0UTU/nNTXkBOYa/P9kVgJ8szEnjaF0Th6r92/0sVGw7XEtLm8v6/5uAICLMzU7hFzfOZvODl/GtpZM5XNPIG5VtrJyXxaovzgv5kz9YAvCbRZ77Ad62u4K7tLmsmsgI94fOmECSljCEuy6dyJvfWsz3PzGU7y+bEbATuPhbeLzKQTA+LZ5RibHWDtCNorJqZmYmMcxGTTUBKjJCGJMQEVZVuJYA/EREKMhJZUtZNS5XYIxWGCjqm9t4r+K0Df9sTICxBOBHC3NSqW5o4cOTgzs4VaDberCGNpda/39jAowlAD/qGBeoqNSqgbxtLqsmJjKCvHHnTflsjHGQJQA/yhwex7jUOGsH6KSorIo545JDZvwUY0KFTwlARJaKyD4RKRWRB7rYfp/XjF+7RKRdRFI8254QkZMisqvTPrkissWzT7GIzPPPS3JWQU4a75RX09bucjqUgHC6sYXdR89Y9Y8xAajHBCAikcDDwJXANGCliEzzLqOqD6lqrqrmAg8Cb6hqx/jIq4ClXRz6x8B3Pfv8q2c56BXkpHK2uY1dR884HUpA2FJegyrWAGxMAPLlCmAeUKqq5araAqwBrr5A+ZXA6o4FVX0T6GqwfAUSPb8nAUd9ijjALfCMc2OzhLltLqsiLiaSmZnJTodijOnElwSQAVR4LVd61p1HROJwf9tf58NxvwY8JCIVwE9wXzkEvRHDhjA5fdhHE5+Eu7fLqpmbnTKgszQZY/pGehoWVUSWA59W1ds9y7cA81T1q12UvQG4WVU/12l9NrBBVad7rfsl7qqidSKyArhDVS/v4ph3AHcApKen561Zs6aXL9Gtvr6ehISEPu3bW0/taeaNijYevjyO6B4mohjMuHrDH3GdbnLxtdfPsWJyNFeN988AcKH8fg0Ei6t3AjUu6F9sixcvLlHV/PM2qOoFH8BCYKPX8oPAg92UXQ98oYv12cCuTuvq+FsCEuBMT7Hk5eVpX23atKnP+/bWxl3HdNz9G3RLWVWPZQczrt7wR1zPbq/Ucfdv0J0Vp/sfkEcov18DweLqnUCNS7V/sQHF2sU51Zfr8q3AJBEZLyIxwI3A850LiUgScAnwnI9J6ainPMASYL+P+wW8+RNSiRB39Uc4KyqtJjE2imljEnsubIwZdD0mAFVtA+4BNgJ7gEJV3S0id4rInV5FlwEvq2qD9/4ishrYDEwWkUoRuc2z6UvAT0XkPeD7eKp5QkHS0GhmZCR9NAFKuCoqr2LBhFQi+zEfqzFm4Pg0H4Cqvgi82Gndo52WV+Hu8tl535XdHPOvQJ6PcQadhTlpPPZWOY0tbV3OOBTqKmoaqag5x22LxjsdijGmG9Y1Y4AU5KTS5lK2Hqx1OhRHdPSCKphoN4AZE6gsAQyQ/OzhREdK2N4PUFRWRVrCECaNDMweFcYYSwADJi4mitlZw8PyfgBVpaismoKc1LAaW92YYGMJYAAVTEzl/SN11DW2Oh3KoCo71cDJs802/IMxAc4SwAAqyElDFbYcCK+rgI7eTzYAnDGBzRLAAMrNSiY2OiLsqoGKyqrJSB5KVspQp0MxxlyAJYABFBMVwdzslLBqCHa5lM3lVv9vTDCwBDDACnLS+PBEPafONjsdyqDYc/wMpxtbKZho9f/GBDpLAAOsoyF0c3l4VAN1VHctnGD1/8YEOksAA2x6RhLDYqMoKg2PaqCismomjIhnVFKs06EYY3pgCWCARUYICyakhsU8wa3tLt7x1P8bYwKfJYBBUJCTyuGaRipqGp0OZUC9f6SOhpZ26/5pTJCwBDAIOk6Iod4O0FH/3zEtpjEmsFkCGAQXpSeQGh8T8vcDFJVVMXV0Iinx/pn9yxgzsCwBDAIRYWFOKkVlVR2zoYWcptZ2ig/WWv2/MUHEEsAgWTQxjRNnmimvaui5cBDafvg0zW0uSwDGBBFLAIOk48QYqt1BN5dVERkhzBuf4nQoxhgf+ZQARGSpiOwTkVIReaCL7feJyA7PY5eItItIimfbEyJyUkR2dbHfVz3H3S0iP+7/ywlcY1PiyEgeGrLdQYvKqpmRkcSw2GinQzHG+KjHBCAikcDDwJXANGCliEzzLqOqD6lqrqrmAg8Cb6hqjWfzKmBpF8ddDFwNzFTVi4Gf9ON1BLyOdoDN5dW4XKHVDtDQ3MaOitNW/WNMkPHlCmAeUKqq5araAqzBfeLuzkpgdceCqr4J1HRR7ivAD1W12VPupM9RB6mCnFRON7ay5/gZp0Pxq3cP1tDmUuv/b0yQkZ56pYjI9cBSVb3ds3wLMF9V7+mibBxQCUz0ugJARLKBDao63WvdDuA53FcHTcA3VXVrF8e8A7gDID09PW/NmjW9fIlu9fX1JCQ4Oz1hbZOLr79+jhsnx7B0fHTAxNWV3sS1Zm8Lrx5q5eHL4xgSObAjgIbC+zWYLK7eCdS4oH+xLV68uERV88/boKoXfADLgce8lm8BftVN2RuAF7pYnw3s6rRuF/BLQHBfZRzAk5C6e+Tl5Wlfbdq0qc/7+tPin2zSL/7vux8tB0pcnfUmrs/88k1d8WjRwAXjJRTer8FkcfVOoMal2r/YgGLt4pzqSxVQJZDltZwJHO2m7I14Vf/4cNxnPPG9C7iAkK9DKMhJ5Z3yalrbXU6H4henG1vYffSMVf8YE4R8SQBbgUkiMl5EYnCf5J/vXEhEkoBLcFfr+OJZYIln34uAGCA0+0h6KchJo6GlnZ2VdU6H4hdbymtQxcb/NyYI9ZgAVLUNuAfYCOwBClV1t4jcKSJ3ehVdBrysqh+700lEVgObgckiUikit3k2PQFM8HQPXQPc6rlUCWkd4+RsDpFZwjaXVREXE8mszGSnQzHG9FKUL4VU9UXgxU7rHu20vAp3l8/O+67s5pgtwM0+xhkyUuJjmDo6kaKyau5ZMsnpcPqtqKyaudkpxETZPYXGBBv71DqgICeV4kO1NLW2Ox1Kv5w828T+k/XW/9+YIGUJwAGLJqbS0uZi2+Fap0Ppl47RTa0B2JjgZAnAAXOzU4iMEIpKg3tYiM1l1STGRjFtTKLToRhj+sASgAOGxUYzMzOJoiBvCC4qq2bBhFQiIwb25i9jzMCwBOCQgpxU3qus41xbcHZ8qqhp5HBNo9X/GxPELAE4pCAnjXaX8mFtcDYEd0xvWTDR6v+NCVaWABySN244MZER7KkO0gRQVk1aQgyTRgbmuCnGmJ5ZAnBIbHQkc8Yls6uqPeiGh1ZVisqqWJiThojV/xsTrCwBOOhzs8ZQWa/c/YdtnGsJniuB8qoGTpxptvp/Y4KcJQAHfWHeWFZOieGl3ce58X+2cOpss9Mh+aToo/7/lgCMCWaWABwkInw6O5pHb85j3/EzXPPw2+w/cdbpsHq0uayKjOShjE2JczoUY0w/WAIIAJ++eBSFX15IS7uLax8p4u0Anjje5VI2l1WzMCfV6v+NCXKWAALEzMxk1t9VwJikodz6xLsUbq1wOqQu7T1+ltrGVqv+MSYEWAIIIJnD41j7lYUszEnlW+t28uOX9gZcD6GOu5cXWgIwJuhZAggwibHRPPH/5rJyXha/eb2Mf1yzPaBGDd1cVs2EtHhGJw11OhRjTD9ZAghA0ZERfH/ZDB68cgobdh7jpsfeobre+R5Cbe0u3jlQY9/+jQkRPiUAEVkqIvtEpFREHuhi+30issPz2CUi7SKS4tn2hIic9Mz81dWxvykiKiI2poAXEeHLl+Twm5vmsOtIHct+U0TZqXpHY3r/SB31zW02/LMxIaLHBCAikcDDwJXANGCliEzzLqOqD6lqrqrmAg8Cb6hqjWfzKmBpN8fOAq4ADvf1BYS6q2aMZs0dC2hsaePa3xR9NAa/Ezr6/y+YkOJYDMYY//HlCmAeUKqq5Z5pHNcAV1+g/EpgdceCqr4J1HRT9ufAt4DAaukMMLPHDmf9XYsYMWwIf//EO6wrqXQkjqKyKqaMGkZqwhBHnt8Y41/S0zzsInI9sFRVb/cs3wLMV9V7uigbB1QCE72uABCRbGCDqk73Wvd54DJVvVdEDgL5qnpeB3gRuQO4AyA9PT1vzZo1vX6RAPX19SQkBN7AZb2Jq6FV+fX2JvbUuLg6J5prJkYPWF/8znG1tCt3v9bIkqwoVk51LgGEwt9xMFlcvROocUH/Ylu8eHGJquaft0FVL/gAlgOPeS3fAvyqm7I3AC90sT4b2OW1HAe8AyR5lg8CaT3FkpeXp321adOmPu87kHobV3Nru36zcIeOu3+D3rt6mza1tg1KXEWlVTru/g366gfHB+T5fBUqf8fBYnH1TqDGpdq/2IBi7eKcGuVD8qgEsryWM4Gj3ZS9Ea/qnwvIAcYD73m+wWYC20Rknqoe92H/sBUTFcGPr59Jdlo8D23cx9HTTfz3LXkMj48Z0OfdXFZFZIQwb7zV/xsTKnxpA9gKTBKR8SISg/sk/3znQiKSBFwCPNfTAVX1fVUdqarZqpqNO8nMsZO/b0SEuxdP5JcrZ7Oj8jTXPlLEwaqGAX3OorJqZmQkMSw2ekCfxxgzeHpMAKraBtwDbAT2AIWqultE7hSRO72KLgNeVtWPnYlEZDWwGZgsIpUicpv/wg9vn581hj/cPp/TjS0s+83bbD3YXVt7/zQ0t7Gj4rQN/2BMiPHpPgBVfVFVL1LVHFX9nmfdo6r6qFeZVap6Yxf7rlTV0aoaraqZqvp4F2WytYsGYNOz/OwU1t+1iOFxMdz0P+/w3I4jfn+OrQdraHOp9f83JsTYncAhIDstnmfuKiB3bDL3rtnBr17b39HY7heby6qJiYwgb9xwvx3TGOM8SwAhIjkuht/fNo9lszP46Ssfct/TO2lpc/nl2EVl1cwem8zQmEi/HM8YExgsAYSQIVGR/GzFLL52+SSeLqnk1ifepa6xtV/HrGtsZdfROqv+MSYEWQIIMSLC1y6/iJ/fMIviQzVc+8jbHK5u7PPxthyoRhUKJloDsDGhxhJAiFo2O5Mnb5tPVb27h9C2w7V9Os7msmqGRkcyKzPZvwEaYxxnCSCEzZ+QyjN3FZAQG8XK327hTzuP9foYRWVVzB2fQkyU/asYE2rsUx3ickYksP6uRczISOLuP2zjkdfLfO4hdOpsMx+eqLf+/8aEKEsAYSAlPoYnb5/P52aN4Ucv7eXBZ96ntb3nHkKby93DP1sCMCY0+TIWkAkBsdGR/OKGXMalxPHrTaVU1p7jNzfPIfECQztsLqtiWGwUF49JGsRIjTGDxa4AwkhEhPDNT0/mx9fPZEt5Ndc/UkRlbfc9hIrKqlkwIZXIiIEZctoY4yxLAGFoRX4W//cP8zhW18Q1DxfxXsXp88pUnXNxqLrRqn+MCWGWAMJUwcQ01t9VQGx0BDf8djMv7fr4QKx7qtvd5ewGMGNCliWAMDZx5DDW37WIKaMS+cpTJfzPm+Uf9RDaU+MiNT6Gi9IDc3YkY0z/WQIIcyOGDWHNHQu4cvoovvfiHr7z3C7a2l3sqW5nYU7qgE05aYxxnvUCMsRGR/LrlXP4cco+Hn2jjN1Hz1DbbMM/GxPqLAEYwN1D6IErpzAuNY5/eXYXYP3/jQl1PlUBichSEdknIqUi8kAX2+8TkR2exy4RaReRFM+2J0TkpIjs6rTPQyKyV0R2ish6EUn2yysy/bJy3lh+/w/zuP6iaMalxjkdjjFmAPWYAEQkEngYuBKYBqwUkWneZVT1IVXNVdVc4EHgDVXtmJ9wFbC0i0O/AkxX1ZnAh579TAAomJjGZyfEWP2/MSHOlyuAeUCpqparaguwBrj6AuVXAqs7FlT1TeC8yWpV9WXPfMMAW4BMn6M2xhjTb9LTwGAicj2wVFVv9yzfAsxX1Xu6KBsHVAITva4AEJFsYIOqTu/mOV4A/qiqT3ax7Q7gDoD09PS8NWvW+PjSPq6+vp6EhMDr0mhx9Y7F1TsWV+8EalzQv9gWL15coqr5521Q1Qs+gOXAY17LtwC/6qbsDcALXazPBnZ1s8+3gfV4ktGFHnl5edpXmzZt6vO+A8ni6h2Lq3csrt4J1LhU+xcbUKxdnFN96QVUCWR5LWcCR7speyNe1T89EZFbgc8Cl3mCNMYYM0h8aQPYCkwSkfEiEoP7JP9850IikgRcAjznyxOLyFLgfuDzqtr3OQuNMcb0SY8JQN0NtfcAG4E9QKGq7haRO0XkTq+iy4CXVbXBe38RWQ1sBiaLSKWI3ObZ9GtgGPCKp/voo354PcYYY3zk041gqvoi8GKndY92Wl6Fu8tn531XdnPMib4GaYwxxv9sLCBjjAlTPXYDDSQicgo41Mfd04AqP4bjLxZX71hcvWNx9U6gxgX9i22cqo7ovDKoEkB/iEixdtUP1mEWV+9YXL1jcfVOoMYFAxObVQEZY0yYsgRgjDFhKpwSwG+dDqAbFlfvWFy9Y3H1TqDGBQMQW9i0ARhjjPm4cLoCMMYY48USgDHGhKmQTwAikiUim0Rkj4jsFpF7nY4JQERiReRdEXnPE9d3nY7Jm4hEish2EdngdCwdROSgiLzvGTqk2Ol4OohIsog87Znhbo+ILAyAmCZ7zdK3Q0TOiMjXnI4LQES+7vmf3yUiq0Uk1umYAETkXk9Mu518r7qaRVFEUkTkFRHZ7/k53B/PFfIJAGgDvqGqU4EFwN2dZzRzSDOwRFVnAbnAUhFZ4GxIH3Mv7rGfAs1idc8+F0h9tX8BvKSqU4BZBMD7pqr79G+z9OUBjbiHXXeUiGQA/wjkq3t+kEjcA0w6SkSmA1/CPQHWLOCzIjLJoXBWcf4sig8Ar6nqJOA1z3K/hXwCUNVjqrrN8/tZ3B/ODGejAs8w3fWexWjPIyBa5EUkE/gM8JjTsQQ6EUkEPgU8DqCqLap62tGgzncZUKaqfb2L3t+igKEiEgXE0f3w8oNpKrBFVRs9A2C+gXuAy0GnXc+ieDXwO8/vvwOu8cdzhXwC8OaZmWw28I7DoQAfVbPsAE4Cr6hqQMQF/BfwLcDlcBydKfCyiJR4ZooLBBOAU8D/eqrMHhOReKeD6qRX83QMJFU9AvwEOAwcA+pU9WVnowJgF/ApEUn1zGx4FR+fB8Vp6ap6DNxfaoGR/jho2CQAEUkA1gFfU9UzTscDoKrtnkv0TGCe5zLUUSLyWeCkqpY4HUsXFqnqHOBK3FV5n3I6INzfZucAj6jqbKABP12e+4NnDo/PA2udjgXAU3d9NTAeGAPEi8jNzkYFqroH+BHwCvAS8B7u6uOQFhYJQESicZ/8n1LVZ5yOpzNPlcHrnF/v54RFwOdF5CCwBlgiIufN1ewEVT3q+XkSd332PGcjAtwz5lV6Xb09jTshBIorgW2qesLpQDwuBw6o6ilVbQWeAQocjgkAVX1cVeeo6qdwV8HsdzomLydEZDSA5+dJfxw05BOAiAju+tk9qvozp+PpICIjRCTZ8/tQ3B+MvY4GBajqg6qaqarZuKsO/qKqjn9DE5F4ERnW8Tvwd7gv2x2lqseBChGZ7Fl1GfCBgyF1tpIAqf7xOAwsEJE4z2fzMgKg0RxAREZ6fo4FriWw3rfngVs9v9+KjzMv9sSnCWGC3CLcE9m/76lvB/hnzyQ3ThoN/E5EInEn4kJVDZgulwEoHVjvPmcQBfxBVV9yNqSPfBV4ylPdUg580eF4APDUZV8BfNnpWDqo6jsi8jSwDXcVy3YCZ/iFdSKSCrQCd6tqrRNBeGZRvBRIE5FK4N+AHwKFnhkVDwPL/fJcNhSEMcaEp5CvAjLGGNM1SwDGGBOmLAEYY0yYsgRgjDFhyhKAMcaEKUsAxhgTpiwBGGNMmPr/ATtkHPFZ2+sYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Zad 2. Napisz program który odczytuje tablicę danych diabetes.csv (wszystkie wiersze i wszystkie kolumny).\n",
    "#Następnie wykonuje szereg eksperymentów z tworzeniem klasyfikatorów i testowaniem ich metodą Cross-Validation, \n",
    "#przy czym jest to zawsze klasyfikator k-NN (te same parametry tworzenia) występujący w powyższym przykładzie przy \n",
    "#atrybucie decyzyjnym: 'decision'. Eksperymenty są wykonywane przy następującej liczbie zbiorów na które\n",
    "#dzielony jest cały zbiór: 2, 3, 4, 5, 6, 7, 8, 9, 10 (chodzi o parametr cv). \n",
    "#Wykonać wykres porównujący jakości klasyfikacji (accuracy) dla wszystkich eksperymemntów i wyciągnąć wniosek \n",
    "#czy i jak parametr cv ma wpływ na jakośc klasyfikacji. Odpowiedni wniosek zapisać słownie \n",
    "#w komentarzu na końcu komórki z rozwiązaniem.\n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = pd.read_csv('./diabetes.csv') \n",
    "\n",
    "features = dataset.iloc[:, :-1]\n",
    "labels = dataset.iloc[:,-1]\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "myNoNeighbors = 5 \n",
    "myMetric = 'euclidean' \n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=myNoNeighbors,metric=myMetric) \n",
    "    \n",
    "def score(cv):\n",
    "    scores = cross_val_score(model, features, np.ravel(labels), cv=cv)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "x = np.arange(2, 11, 1)\n",
    "y = np.array([score(cv) for cv in x])\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#Od parametru cv=4 dokladnosc zaczela wzrastac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Wizualizacja jakości klasyfikatora za pomocą krzywej ROC\n",
    "\n",
    "Krzywa ROC  (ang. Receiver Operating  Characteristic)  jest  narzędziem  do oceny  poprawności działania klasyfikatora. Zapewnia ona łączny opis  jego  czułości i specyficzności w zależności od ustalonego progu prawdopodobieństwa. Ten  sposób  wspomagania oceny efektywności klasyfikatorów \n",
    "jest szeroko  wykorzystywany  w różnych  zastosowaniach. Krzywa ROC jest stosowana, gdy mamy dane z decyzją binarną, tzn. gdzie atrybut decyzyjny ma tylko 2 wartości, czyli są tylko dwie klasy decyzyjne. Klasy te nazywamy: klasą pozytywna i klasą negatywną (możemy wskazać która klasa jest klasa pozytywną). \n",
    "\n",
    "Krzywa ROC pozwala na porównanie obecności obiektów tzw. prawdziwie pozytywnych (należą do klasy pozytywnej i tam zostały sklasyfikowane) i fałszywie pozytywnych (należą do klasy negatywnej, ale zostały sklasyfikowane do pozytywnej). Porównanie to odbywa się na różnych poziomach prawdopodobieństwa $t_p$ tego, że klasyfikowany obiekt testowy jest w klasie pozytywnej. Ten ustalony poziom $t_p$ jest tak wykorzystywany, że obiekt testowy jest klasyfikowany do klasy pozytywnej, gdy prawdopodobieństwo dla tego obiektu wyliczone przez klasyfikator jest większe od $t_p$; w przeciwnym przypadku obiekt testowy jest klasyfikowany do klasy negatywnej.\n",
    "\n",
    "Przy ustalonym poziomie prawdopodobieństwa, wylicza się wartość tzw. *czułości* (liczba obiektów poprawnie sklasyfikowanych z klasy pozytywnej / liczba wszystkich obiektów z klasy pozytywnej) oraz *specyficzności* (liczba obiektów poprawnie sklasyfikowanych z klasy negatywnej / liczba wszystkich obiektów z klasy negatywnej). Po każdym takim eksperymencie zaznacza się jeden punkt na krzywej ROC o współrzędnych `(czułość, 1-specyficzność)`\n",
    "\n",
    "Dzięki wygenerowaniu krzywej ROC można zobaczyć, jak przedstawia się efektywność modelu w zakresie dokładności klasyfikacji. Klasyfikator poprawnie prognozujący większość obiektów będzie miał na wykresie postać jednolitej linii, już na początku skierowanej w górę. Z kolei klasyfikator często prognozujący niepoprawnie klasę obiektów testowych, na wykresie będzie miał postać linii rosnącej wolniej. Wreszcie, klasyfikator prognozujący obiekty w sposób losowy na wykresie będzie miał postać linii ukośnej (prosta $y=x$). Najlepszym sposobem porównania jakości klasyfikatorów jest porównanie pól pod krzywą ROC. Pole to oznaczamy przez AUC (ang. Area Under Curve). Im lepszy model, tym AUC jest większe i zbliża sie do maksimum, które wynosi 1.0 (wypełnienie całego kwadratu o boku 1). Warość AUC=1.0 odpowiada klasyfikatorowi, który nigdy się nie myli.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Użyte progi prawdopodobieństwa: [2.         1.         0.66666667 0.33333333 0.        ]\n",
      "AUC= 0.6389751552795031\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "\n",
    "# Utworzenie klasyfikatora.\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,metric='euclidean') \n",
    "\n",
    "# Wytrenowanie modelu.\n",
    "classifier.fit(features_train, np.ravel(labels_train))\n",
    "\n",
    "#Policzenie pola pod krzywą ROC\n",
    "labels_predicted = classifier.predict(features_test)\n",
    "auc = metrics.roc_auc_score(labels_test, labels_predicted) \n",
    "\n",
    "#Policzenie prawdopodobieństw\n",
    "target_probabilities = classifier.predict_proba(features_test)[:,1]\n",
    "\n",
    "#Wyznaczenie danych do krzywej ROC\n",
    "czulosci, specyficznosci, progi = metrics.roc_curve(labels_test,target_probabilities,pos_label=2)\n",
    "\n",
    "print(\"Użyte progi prawdopodobieństwa:\",progi)\n",
    "print(\"AUC=\",auc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8)) #Rozmiary okna z wykresem\n",
    "plt.plot(czulosci, specyficznosci)\n",
    "plt.title(\"Krzywa ROC\")\n",
    "plt.xlabel(\"1-Specyficzność\")\n",
    "plt.ylabel(\"Czułość\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generowanie decyzji dla nowych obiektów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decyzje wygenerowane: [2 2 2 2 2 2 1 2 2 1]\n",
      "Decyzje oryginalne:   [2 1 2 1 1 2 1 1 2 1]\n",
      "Kolejność klas decyzyjnych: [1 2]\n",
      "Prawdopodobieństwa: 0.3333 0.6667   Oryginalna decyzja: 2 Wygenerowana decyzja: 2  -  sukces\n",
      "Prawdopodobieństwa: 0.3333 0.6667   Oryginalna decyzja: 1 Wygenerowana decyzja: 2  -  porażka\n",
      "Prawdopodobieństwa: 0.0000 1.0000   Oryginalna decyzja: 2 Wygenerowana decyzja: 2  -  sukces\n",
      "Prawdopodobieństwa: 0.0000 1.0000   Oryginalna decyzja: 1 Wygenerowana decyzja: 2  -  porażka\n",
      "Prawdopodobieństwa: 0.3333 0.6667   Oryginalna decyzja: 1 Wygenerowana decyzja: 2  -  porażka\n",
      "Prawdopodobieństwa: 0.3333 0.6667   Oryginalna decyzja: 2 Wygenerowana decyzja: 2  -  sukces\n",
      "Prawdopodobieństwa: 0.6667 0.3333   Oryginalna decyzja: 1 Wygenerowana decyzja: 1  -  sukces\n",
      "Prawdopodobieństwa: 0.3333 0.6667   Oryginalna decyzja: 1 Wygenerowana decyzja: 2  -  porażka\n",
      "Prawdopodobieństwa: 0.0000 1.0000   Oryginalna decyzja: 2 Wygenerowana decyzja: 2  -  sukces\n",
      "Prawdopodobieństwa: 0.6667 0.3333   Oryginalna decyzja: 1 Wygenerowana decyzja: 1  -  sukces\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Funkcja pomocnicza do formatowania liczb (4 miejsca po przecinku)\n",
    "def myformat(number):\n",
    "    return \"{0:.4f}\".format(float(number))\n",
    "\n",
    "\n",
    "#Odczytanie tablicy treningowej i testowej\n",
    "datasetTrain = pd.read_csv('./dane/serce_train.csv')\n",
    "datasetTest = pd.read_csv('./dane/serce_test.csv')\n",
    "\n",
    "noColumn = datasetTrain.shape[1]\n",
    "\n",
    "features_train = datasetTrain.iloc[:,:noColumn-1] #Część warunkowa tablicy treningowej\n",
    "labels_train = datasetTrain.iloc[:,[noColumn-1]] #Kolumna decyzyjna tablicy treningowej\n",
    "\n",
    "features_test = datasetTest.iloc[:,:noColumn-1] #Część warunkowa tablicy testowej\n",
    "labels_test_orig = datasetTest.iloc[:,[noColumn-1]] #Kolumna decyzyjna tablicy testowej\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3,metric='euclidean') \n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora\n",
    "\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Testowanie tablicy testowej\n",
    "vector_labels_test_orig = np.ravel(labels_test_orig)\n",
    "\n",
    "print(\"Decyzje wygenerowane:\",labels_predicted)\n",
    "print(\"Decyzje oryginalne:  \",vector_labels_test_orig)\n",
    "\n",
    "labels_predicted_proba = model.predict_proba(features_test) #Wyliczenie prawdopodonieństwa poszczególnych decyzji\n",
    "\n",
    "print(\"Kolejność klas decyzyjnych:\",model.classes_)\n",
    "\n",
    "for i in range(0,len(labels_predicted_proba)): #Wypisanie prawdopodobieństw dla klas\n",
    "    p1 = labels_predicted_proba[i][0]\n",
    "    p2 = labels_predicted_proba[i][1]\n",
    "    wynik = \"sukces\"\n",
    "    if  labels_predicted[i]!=vector_labels_test_orig[i]: wynik = \"porażka\"\n",
    "    print(\"Prawdopodobieństwa:\",myformat(p1),myformat(p2),\n",
    "          \"  Oryginalna decyzja:\",vector_labels_test_orig[i],\"Wygenerowana decyzja:\",labels_predicted[i],\" - \",wynik)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uzyskane decyzje: [0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Zad 3. Napisz program który odczytuje tablicę danych rezygnacje.csv oraz wybiera z niej wszystkie wiersze oraz\n",
    "#kolumny: CZAS_POSIADANIA, PLAN_MIEDZY, POCZTA_G, L_WIAD_POCZTA_G, L_POL_BIURO, REZYGN. \n",
    "#Następnie wykonuje eksperyment, którego celem jest wygenerowanie wartości decyzji dla obiektów testowych \n",
    "#z pliku czy_zrezygnuja.csv. Klasyfikator jest tworzony dla tablicy rezygnacje.csv metodą k-NN z użyciem tych samych \n",
    "#parametrów tworzenia jak w powyższym przykładzie i przy atrybucie decyzyjnym 'REZYGN'. \n",
    "#Wygenerowane decyzję są dopisywane jako ostatnia kolumna do zbioru odczytanego z pliku czy_zrezygnuja.csv, \n",
    "#po czym zmodyfikowany zbiór danych (z dodaną kolumną) jest zapisywany do pliku czy_zrezygnuja_dec.csv.\n",
    "#UWAGA: W danych z pliku czy_zrezygnuja.csv nie ma atrybutu decyzyjnego.\n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "dataSet = pd.read_csv('./rezygnacje.csv', usecols=['CZAS_POSIADANIA', 'PLAN_MIEDZY', 'POCZTA_G', 'L_WIAD_POCZTA_G', 'L_POL_BIURO', 'REZYGN'])\n",
    "dataSetTest = pd.read_csv('./czy_zrezygnuja.csv', usecols=['CZAS_POSIADANIA', 'PLAN_MIEDZY', 'POCZTA_G', 'L_WIAD_POCZTA_G', 'L_POL_BIURO'])\n",
    "dataSetTestOrg = pd.read_csv('./czy_zrezygnuja.csv')\n",
    "\n",
    "features_train = dataSet.iloc[:, :-1]\n",
    "labels_train = dataSet.iloc[:, -1]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
    "model = model.fit(features_train, np.ravel(labels_train))\n",
    "\n",
    "predict = model.predict(dataSetTest)\n",
    "\n",
    "result = dataSetTestOrg.join(pd.DataFrame(predict, columns=['REZYGN']))\n",
    "\n",
    "result.to_csv(\"rezygn_dec.csv\", index=False)\n",
    "\n",
    "print(\"Uzyskane decyzje:\", predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikator oparty na drzewie decyzyjnym\n",
    "\n",
    "Klasyfikatory oparte na drzewach są szeroką i popularną rodziną powiązanych ze sobą i pozbawionych\n",
    "parametrów nadzorowanych metod klasyfikowania i regresji. Podstawą tych klasyfikatorów\n",
    "jest tak zwane drzewo decyzyjne, w którym zostały połączone serie reguł decyzyjnych, na przykład\n",
    "„jeśli płeć to mężczyzna, to…”. Otrzymany wynik z grubsza przypomina odwrócone drzewo,\n",
    "w którym pierwsza reguła decyzyjna znajduje się na górze, a kolejne rozpościerają się poniżej.\n",
    "W drzewie decyzyjnym każda reguła występuje w węźle decyzyjnym, a reguły tworzą gałęzie prowadzące\n",
    "do nowych węzłów. Gałąź bez reguły decyzyjnej na końcu nosi nazwę liścia.\n",
    "Jednym z powodów dużej popularności modeli opartych na drzewie jest łatwość ich interpretacji.\n",
    "Tak naprawdę drzewo decyzyjne może zostać dosłownie narysowane w jego pełnej postaci, aby w ten sposób przygotować niezwykle intuicyjny model. Z prostych systemów drzew powstały różne rozszerzenia,jak chocby algorytm losowego lasu (patrz dalej).\n",
    "\n",
    "Klasyfikator drzewa decyzyjnego, realizowany za pomocą klasy `DecisionTreeClassifier`, próbuje wyszukać regułę decyzyjną pozwalającą na największe zmniejszenie niejednorodności w węźle. Wprawdzie istnieje pewna liczba pomiarów niejednorodności, ale domyślnie DecisionTreeClassifier używa wskaźnika Giniego.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba kolumn= 14\n",
      "Dokładnośc klasyfikacji= 0.7222222222222222\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.83      0.77        92\n",
      "           2       0.72      0.59      0.65        70\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.72      0.71      0.71       162\n",
      "weighted avg       0.72      0.72      0.72       162\n",
      "\n",
      "====== MACIERZ POMYŁEK (confusion matrix) +=========\n",
      "[[76 16]\n",
      " [29 41]]\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "print(\"Liczba kolumn=\",noColumn)\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "#PARAMETRY TWORZENIA DRZEWA\n",
    "\n",
    "my_criterion = \"gini\" #Kryterium podziału węzła drzewa podczas budowy drzewa: 'gini', 'entropy' \n",
    "\n",
    "#Maksymalna głebokość drzewa. Wartość None powoduje, że drzewo będzie się rozrastało aż do\n",
    "#chwili, gdy wszystkie liście będą jednorodne (składające się z obiektów mających taką samą decyzję). \n",
    "#Z kolei wartość w postaci liczby całkowitej praktycznie oznacza „przycięcie” drzewa do podanej głębokości\n",
    "my_max_depth = 5 \n",
    "\n",
    "#Minimalna liczba obserwacji w węźle, zanim nastąpi jego rozgałęzienie. Jeżeli wartością jest\n",
    "#liczba całkowita, określa czyste minimum, zaś liczba zmiennoprzecinkowa określa wielkość\n",
    "#procentową wszystkich obserwacji.\n",
    "my_min_samples_split = 10 \n",
    "\n",
    "#Minimalna liczba obserwacji wymaganych do umieszczenia na liściu. Używane są takie same\n",
    "#argumenty jak w przypadku min_samples_split.\n",
    "my_min_samples_leaf = 10\n",
    "\n",
    "#Maksymalna liczba liści.\n",
    "my_max_leaf_nodes = 30\n",
    "\n",
    "#Minimalny wymagany spadek niejednorodności (zwieksenie czystości), aby został utworzoby podział węzła\n",
    "my_min_impurity_decrease = 0.02\n",
    "\n",
    "#Wprawdzie dobrze jest wiedzieć o istnieniu wymienionych parametrów, ale w większości przypadków\n",
    "#używane będą tylko max_depth i min_impurity_decrease.\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "model =  DecisionTreeClassifier(criterion=my_criterion,\n",
    "                               max_depth=my_max_depth,\n",
    "                               min_samples_split=my_min_samples_split,                                \n",
    "                               min_samples_leaf = my_min_samples_leaf,\n",
    "                               max_leaf_nodes = my_max_leaf_nodes,\n",
    "                               min_impurity_decrease = my_min_impurity_decrease)\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n",
    "print(\"====== MACIERZ POMYŁEK (confusion matrix) +=========\")\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja drzewa decyzyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"800\"\n",
       "            src=\"serce1.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9eec7ba350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Przykład demonstrujący wizualizację drzewa decyzyjnego\n",
    "#Dla poprawnego działania tego przykładu należy:\n",
    "# - zainstalować program Graphviz ze strony: https://graphviz.gitlab.io/download/\n",
    "# - zainstalowac pakiet graphviz  \n",
    "    \n",
    "    \n",
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv')\n",
    "noColumn = dataset.shape[1]\n",
    "maximal_depth = 3\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "#print(features.head())\n",
    "#print(labels.head())\n",
    "\n",
    "features_names = list(features)\n",
    "\n",
    "#Pozyskiwanie wartości decyzji\n",
    "class_names_ordered = sorted(np.unique(labels))\n",
    "my_class_names = []\n",
    "for i in range(0,len(class_names_ordered)):\n",
    "    my_class_names.append(str(class_names_ordered[i]))\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion = \"gini\",max_depth=maximal_depth, min_samples_leaf=5, class_weight=\"balanced\")\n",
    "clf.fit(features, labels)\n",
    "\n",
    "\n",
    "#Generowanie wizualizacji drzewa\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(\n",
    "    decision_tree=clf,\n",
    "    out_file=dot_data,\n",
    "    feature_names=features_names,\n",
    "    class_names=my_class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=True\n",
    ")\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "graph.write_pdf('serce1.pdf') #Zapis drzewa na dysk\n",
    "IFrame(\"serce1.pdf\", width=900, height=800) #Otwarcie drzewa w przeglądarce\n",
    "\n",
    "#Tak mozna na lokalnym komputerze\n",
    "#os.startfile('serce1.pdf') #Otwarcie drzewa w standardowej przeglądarce do PDF-ów\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naiwny klasyfikator bayesowski\n",
    "\n",
    "Metody probabilistyczne klasyfikacji obiektów można przedstawić za pomocą następującego schematu ogólnego:\n",
    "\n",
    "1. Dla danego obiektu o mającego wartości atrybutów warunkowych równe a1 = v1, ... , an = vn, oszacuj prawdopodobieństwa Pi, że obiekt ten przynależy do klasy decyzyjnej di.\n",
    "\n",
    "2. Wybierz największą wartość Pmax spośród tych prawdopodobieństw.\n",
    "\n",
    "3. Przypisz obiektowi o klasę decyzyjną dmax odpowiadającą prawdopodobieństwu Pmax.\n",
    "\n",
    "\n",
    "Przykładem takiego algorytmu jest klasyfikator bayesowski. Jeśli mamy tablicę decyzyjną T mająca atrybuty warunkowe $a_1$,.., $a_m$ i decyzyjny $d$ z wartościami $d_1$,..., $d_k$, to prawdopodobieństwo, że obiekt testowy $u=(u_1,...,u_m)$ należy do klasy decyyzjnej $d_i$ na podstawie twierdzenia Bayesa wyraża się wzorem:\n",
    "\n",
    "$$P(d_i|u_1,...,u_m) = \\frac{P(u_1,...,u_m|d_i) \\cdot P(d_i)}{P(u_1,...,u_m)}$$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "- $P(u_1,...,u_m|d_i)$ to prawdopodobięństwo, że w przypadku, gdy wartości atrybutów \n",
    "$a_1$,.., $a_m$ mają wartości $u_1,...,u_m$, to wartośc decyzji jest $d_i$,\n",
    "\n",
    "- $P(d_i)$ to prawdopodobieństwo znalezienia w T obiektu z klasy decyzyjnej $d_i$,\n",
    "\n",
    "- $P(u_1,...,u_m)$ to prawdopodobieństwo znalezienia w T obiektu, że wartości atrybutów \n",
    "$a_1$,.., $a_m$ dla tego obiektu mają wartości $u_1,...,u_m$.\n",
    "\n",
    "Jeśli chodzi o występujące w mianowniku prawdopodobieństwo  $P(u_1,...,u_m)$, to dla ustalonego obiektu testowego jest\n",
    "ono stałe przy rozważaniu różnych klas decyzyjnych. Dlatego w dalszych rozważaniach dotyczących budowy klasyfikatora możemy je pominąć. \n",
    "\n",
    "Ponadto, omawiana metoda tworzenia klasyfikatora zakłada brak zależności pomiędzy atrybutami warunkowymi. \n",
    "Dlatego, korzystając ze wzoru na prawdopodobieństwo zdrzeń niezależnych, powyższy wzór można zapisac jako: \n",
    "\n",
    "$$P(d_i|u_1,...,u_m) = P(d_i) \\cdot \\prod_{i=1}^{m} P(u_i|d_i)$$\n",
    "\n",
    "Wielkość klas decyzyjnych w danych treningowych jest stała. Zatem dla wyznaczenia wartości decyzji dla obiektu testowego trzeba wyznaczyc $m$ prawdopodobieństw związanych z wartościmi atrybutów warunkowych obiektu testowego.\n",
    "\n",
    "Dla policzenia tego prawdopodonięństwa dla każdej cechy w danych trzeba przyjąć założenie o rozkładzie statystycznym prawdopodobieństwa $P(u_i|d_i)$. Najczęściej spotykane rodzaje rozkładów to Gaussowski dla przypadku atrybutów ciągłych (atrybuty numeryczne) i wielomianowy dla przypadku atrybutów o wartościach dyskretnych (atrybuty symboliczne).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Naiwny klasyfikator bayesowski Gaussa (dla cech ciągłych)\n",
    "\n",
    "Najczęściej spotykany rodzaj naiwnego klasyfikatora bayesowskiego to naiwny klasyfikator bayesowski\n",
    "Gaussa. W tym klasyfikatorze przyjmowane jest założenie, że prawdopodobieństwo $P(u_i|d_i$ można określić za pomocą rozkładu normalnego. Dlatego naiwny klasyfikator bayesowski Gaussa sprawdza się najlepiej w przypadkach, w których\n",
    "wszystkie cechy są ciągłe.\n",
    "\n",
    "Jednym z ciekawszych aspektów naiwnego klasyfikatora bayesowskiego Gaussa jest to, że pozwala on\n",
    "na wykorzystanie wcześniejszego przekonania dotyczącego klasy docelowej. To wymaga użycia parametru\n",
    "*priors* egzemplarza klasy `GaussianNB`, który pobiera listę prawdopodobieństwa przypisanego poszczególnym\n",
    "klasom wektora docelowego.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładnośc klasyfikacji= 0.8518518518518519\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.89      0.87        92\n",
      "           2       0.85      0.80      0.82        70\n",
      "\n",
      "    accuracy                           0.85       162\n",
      "   macro avg       0.85      0.85      0.85       162\n",
      "weighted avg       0.85      0.85      0.85       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "\n",
    "model = GaussianNB() #Wersja bez przekonania dotyczącego klasy docelowej\n",
    "\n",
    "#priors=[0.25,0.75] #Wersja z przekonaniem dotyczącym klasy docelowej\n",
    "#model = GaussianNB(priors)\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładnośc klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wielomianowy naiwny klasyfikator bayesowski\n",
    "\n",
    "Wielomianowy naiwny klasyfikator bayesowski działa podobnie jak gaussowski, ale przyjmuje się założenie\n",
    "o wielomianowym rozkładzie cech. W praktyce oznacza to, że omawiany klasyfikator jest\n",
    "powszechnie stosowany w przypadku atrybutów dyskretnych\n",
    "\n",
    "Podobnie jak w przypadku klasyfikatora bayesowskiego Gaussa, także można wykorzystywać wcześniejsze przekonanie dotyczące klasy docelowej, co wymaga użycia parametru *class_prior*, który pobiera listę prawdopodobieństwa przypisanego poszczególnym klasom wektora docelowego.\n",
    "\n",
    "Patrz także:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność klasyfikacji= 0.7469135802469136\n",
      "========= PEŁNE WYNIKI KLASYFIKACJI ================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.76      0.77        92\n",
      "           2       0.70      0.73      0.71        70\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.74      0.74      0.74       162\n",
      "weighted avg       0.75      0.75      0.75       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv') #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset.shape[1] #Ustalenie liczby kolumn w danych\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels = dataset.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "#Podział tablicy treningowej w proporcji: 60% do treningu i 40% do testu\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych (jesli wartość nie występuje, ziarno jest losowe])\n",
    "#Ustalone ziarno pozwala na uzyskanie powtarzalnych wyników eksperymentów\n",
    "\n",
    "datasets = train_test_split(features, labels, test_size=0.6, random_state=1234)\n",
    "\n",
    "features_train = datasets[0]\n",
    "features_test = datasets[1]\n",
    "labels_train = datasets[2]\n",
    "labels_test = datasets[3]\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "#model = MultinomialNB(class_prior=[0.25, 0.5])\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "#Policzenie jakości klasyfikacji przez porównanie: labels_predicted i labels_test \n",
    "accuracy = metrics.accuracy_score(labels_test, labels_predicted) \n",
    "\n",
    "print(\"Dokładność klasyfikacji=\" ,accuracy)\n",
    "\n",
    "print(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "\n",
    "report = classification_report(labels_test, labels_predicted)\n",
    "print(report )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie działania klasyfikatorów tworzonych czterema metodami dla ustalonego zestawu parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.845679012345679 GaussianNB\n",
      "2. 0.7962962962962963 BernoulliNB\n",
      "3. 0.7654320987654321 DecisionTree\n",
      "4. 0.6728395061728395 KNN\n"
     ]
    }
   ],
   "source": [
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #Ignorowanie ostrzeżeń\n",
    "\n",
    "dataset = pd.read_csv('./dane/serce.csv')\n",
    "\n",
    "noColumn = dataset.shape[1]\n",
    "\n",
    "features = dataset.iloc[:,:noColumn-1]\n",
    "labels = dataset.iloc[:,[noColumn-1]]\n",
    "\n",
    "#Podział tablicy na część treningową i testową\n",
    "data = train_test_split(features, labels, test_size=0.6, random_state=12345)\n",
    "features_train = data[0]\n",
    "features_test = data[1]\n",
    "labels_train = data[2]\n",
    "labels_test = data[3]\n",
    "\n",
    "#========DEFINIOWANIE MODELI i ich nazw ===============\n",
    "\n",
    "models = []\n",
    "modelNameList = []\n",
    "\n",
    "#Klasyfikator k najbliższych sąsiadów\n",
    "model = KNeighborsClassifier(n_neighbors=3,metric = 'euclidean')\n",
    "models.append(model)\n",
    "modelNameList.append(\"KNN\")\n",
    "\n",
    "#Naiwny Bayes traktujący atrybuty jako atrybuty z ciągłymi wartościami (dobry dla numerycznych)\n",
    "model = GaussianNB()\n",
    "models.append(model)\n",
    "modelNameList.append(\"GaussianNB\")\n",
    "\n",
    "#Naiwny Bayes traktujący atrybuty jako atrybuty z dyskretnymi wartościami (dobry dla symbolicznych)\n",
    "model = BernoulliNB()\n",
    "models.append(model)\n",
    "modelNameList.append(\"BernoulliNB\")\n",
    "\n",
    "#Drzewo decyzyjne\n",
    "model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "models.append(model)\n",
    "modelNameList.append(\"DecisionTree\")\n",
    "\n",
    "\n",
    "#===========================================\n",
    "\n",
    "results = []\n",
    "#Testowanie wszystkich klasyfikatorów\n",
    "for i in range(0,len(models)):\n",
    "    model = models[i]\n",
    "    model.fit(features_train, np.ravel(labels_train))\n",
    "    labels_predicted = model.predict(features_test)\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)    \n",
    "    locList = []; locList.append(accuracy); locList.append(modelNameList[i])\n",
    "    results.append(locList)\n",
    "\n",
    "def myFunc(result):\n",
    "    return result[0]  #Funkcja porównuje według accuracy\n",
    "\n",
    "#Sortowanie wyników\n",
    "results.sort(reverse=True, key=myFunc)\n",
    "\n",
    "#Wypisanie posortowanych wyników\n",
    "for i in range(0,len(results)):\n",
    "    result = results[i]\n",
    "    print(str(i+1)+\".\",result[0],result[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zad 4. Napisz program który odczytuje tablicę danych rezygnacje.csv oraz wybiera z niej wszystkie wiersze oraz\n",
    "#kolumny: CZAS_POSIADANIA, PLAN_MIEDZY, POCZTA_G, L_WIAD_POCZTA_G, L_POL_BIURO, REZYGN. \n",
    "#Następnie wykonuje szereg eksperymentów tak jak w poprzednim przykładzie celem ustalenia który klasyfikator \n",
    "#uzyskuje najlepsze wyniki. Poeksperymentować trochę z parametrami tych 4 klasyfikatorów, aby uzyskać lepszą jakość\n",
    "#klasyfikacji. Wykonać wykres porównujący jakości klasyfikacji (accuracy) dla wszystkich 4 klasyfikatorów \n",
    "#i wyciągnąć wniosek który klasyfikator jest najlepszy.\n",
    "#Wygenerować krzywe ROC dla wszystkich 4 klasyfikatorów. \n",
    "#Czy rankingi klasyfikatorów z punktu wudzenia accuracy oraz AUC pokrywają się?\n",
    "#Odpowiedni wniosek zapisać słownie w komentarzu na końcu komórki z rozwiązaniem.\n",
    "#Sprawdzić czy dodanie innych atrybutów warunkowych, które zostały wcześniej usunięte, poprawi jakość klasyfikatorów.\n",
    "#Odpowiedni wniosek na ten temat także zapisać słownie w komentarzu na końcu komórki z rozwiązaniem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zad 5. Pewien bank zgromadził dane o kredytach, które oferował swoim klientom oraz informacje czy każdy z tych \n",
    "#kredytów był dobrym kredytem dla banku (klient spłacił kredyt) lub złym kredytem dla banku (klient nie spłacił \n",
    "#kredytu).  Dane te mają posłużyć do automatycznego  wspomagania podejmowania decyzji w zakresie przyznawania \n",
    "#kredytów nowym klientom za pomocą klasyfikatorów. W celu przeprowadzenia testu efektywności wybranych \n",
    "#klasyfikatorów metodą train&test dane podzielono na dwie części, które są dostępne w plikach w formacie CSV: \n",
    "# dz1_train.csv i dz1_test.csv. \n",
    "#\n",
    "#Przeprowadzić test tablicy dz1_test.csv metodą train&test dla następujących klasyfikatorów:\n",
    "#\n",
    "#1. klasyfikator oparty na metodzie k-NN biorący pod uwage 5 najbliższych sąsiadów i metrykę euklidesową,\n",
    "#\n",
    "#2. klasyfikator oparty na drzewie decyzyjnym skonstruowanym według miary entropijnej podziału węzła, \n",
    "# maksymalną głebokością drzewa równą 6 i minimalnym wymaganym spadkiem niejednorodności równym 0.01 \n",
    "# (pozostałe parametry na ustawieniach standardowych).\n",
    "#\n",
    "#Wypisać dokładność klasyfikacji obydwu klasyfikatorów (accuracy) dla całej tablicy testowej oraz \n",
    "#dla obydwu klas decyzyjnych z osobna (recall) (jest to 6 liczb).\n",
    "#\n",
    "#Wyniki i odpowiednie wnioski na temat porównania klasyfikatorów odnośnie ich jakości zapisać w komentarzu na \n",
    "#końcu komórki z rozwiązaniem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suma_kosztu= 99\n"
     ]
    }
   ],
   "source": [
    "#Zad 6. Wyznaczyć jakość dwóch klasyfikatorów wyznaczonych w poprzednim kroku poprzez wyliczenie ich kosztów \n",
    "#marketingowych  błędnie podjętych decyzji przez program dla tablicy dz1_test.csv. \n",
    "#Jeśli mamy dwie wartości decyzji: 1 (decyzja pozytywna - dobry kredyt) i 0 (decyzja negatywna - zły kredyt), \n",
    "#to przy klasyfikacji obiektu testowego możliwe są 4 następujące przypadki:\n",
    "#\n",
    "#1. Prawdziwa klasyfikacja negatywna – nie przyznajemy kredytu i jest to decyzja poprawna, bo klient i tak by go \n",
    "# nie spłacił (koszt=0).\n",
    "#\n",
    "#2. Prawdziwa klasyfikacja pozytywna – przyznajemy kredyt i jest to decyzja poprawna bo klient go spłaci (koszt=0).\n",
    "#\n",
    "#3. Fałszywa klasyfikacja negatywna – nie przyznajemy kredytu (klasyfikator wygenerował 0), ale nie jest to decyzja \n",
    "# poprawna, bo klient spłaciłby kredyt (koszt=1).\n",
    "#\n",
    "#4. Fałszywa klasyfikacja pozytywna – przyznajemy kredyt (klasyfikator wygenerował 1), ale nie jest to decyzja poprawna,\n",
    "# bo ten klient nie spłaci kredytu (koszt=5)\n",
    "#\n",
    "#Zauważmy, że koszt fałszywej klasyfikacji pozytywnej jest wyższy od kosztu fałszywej klasyfikacji negatywnej, \n",
    "#gdyż w przypadku fałszywej klasyfikacji pozytywnej bank więcej straci ponosząc koszty zajmowania się nie spłaconym \n",
    "#kredytem (np. koszty wynajęcia firmy w celu przeprowadzenia egzekucji komorniczej). Sumaryczny koszt marketingowy \n",
    "#dla całej próbki testowej jest po prostu sumą kosztów marketingowych poniesionych dla wszystkich obiektów testowych. \n",
    "#Dany klasyfikator jest lepszy, gdy ma mniejszy sumaryczny koszt marketingowy.  Podaj sumaryczne koszty marketingowe \n",
    "#dla dwóch wymienionych wyżej klasyfikatorów.\n",
    "#\n",
    "#Wyniki i odpowiednie wnioski zapisać w komentarzu na końcu komórki z rozwiązaniem.\n",
    "\n",
    "\n",
    "#Polecenie usuwa wszystkie zmienne z pamięci \n",
    "%reset -f \n",
    " \n",
    "#Import potrzebnych pakietów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "dataset_train = pd.read_csv('./dane/dz1_train.csv',sep=\";\") #Odczytanie zbioru danych\n",
    "dataset_test = pd.read_csv('./dane/dz1_test.csv',sep=\";\") #Odczytanie zbioru danych\n",
    "\n",
    "\n",
    "noColumn = dataset_train.shape[1] #Ustalenie liczby kolumn w danych\n",
    "\n",
    "features_train = dataset_train.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels_train = dataset_train.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "features_test = dataset_test.iloc[:,:noColumn-1] #Wyodrębnienie częśći warunkowej danych\n",
    "labels_test = dataset_test.iloc[:,[noColumn-1]] #Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "\n",
    "#model = GaussianNB() #Wersja bez przekonania dotyczącego klasy docelowej\n",
    "#model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "#model = KNeighborsClassifier(n_neighbors=3,metric = 'euclidean')\n",
    "#model = GradientBoostingClassifier()  \n",
    "model = AdaBoostClassifier() \n",
    "\n",
    "my_criterion = \"gini\" #Kryterium podziału węzła drzewa podczas budowy drzewa: 'gini', 'entropy' \n",
    "\n",
    "#Maksymalna głebokość drzewa. Wartość None powoduje, że drzewo będzie się rozrastało aż do\n",
    "#chwili, gdy wszystkie liście będą jednorodne (składające się z obiektów mających taką samą decyzję). \n",
    "#Z kolei wartość w postaci liczby całkowitej praktycznie oznacza „przycięcie” drzewa do podanej głębokości\n",
    "my_max_depth = 5 \n",
    "\n",
    "#Minimalna liczba obserwacji w węźle, zanim nastąpi jego rozgałęzienie. Jeżeli wartością jest\n",
    "#liczba całkowita, określa czyste minimum, zaś liczba zmiennoprzecinkowa określa wielkość\n",
    "#procentową wszystkich obserwacji (domyślnie 2).\n",
    "my_min_samples_split = 10 \n",
    "\n",
    "#Minimalna liczba obserwacji wymaganych do umieszczenia na liściu (domyślnie 1).\n",
    "my_min_samples_leaf = 2\n",
    "\n",
    "#Maksymalna liczba liści.\n",
    "my_max_leaf_nodes = 30\n",
    "\n",
    "#Minimalny wymagany spadek niejednorodności (zwieksenie czystości), aby został utworzoby podział węzła\n",
    "my_min_impurity_decrease = 0.02\n",
    "\n",
    "\n",
    "\n",
    "#Maksymalna liczba cech uwzględnianych w każdym węźle. Domyślnie będzie to sqrt(p) cech, gdzie p\n",
    "#to całkowita liczba cech.\n",
    "my_max_features = 10\n",
    "\n",
    "#Określenie, czy próbki mają być ze zwracaniem. Wartością domyślną tego parametru jest True.\n",
    "my_bootstrap = True\n",
    "\n",
    "#Określenie liczby drzew decyzyjnych do utworzenia. Wartością domyślną tego parametru jest 100.\n",
    "my_n_estimators = 20\n",
    "\n",
    "#Okreslenie liczby wykorzystywanych rdzeni podczas obliczeńn_jobs. Przypisanie mu wartości -1\n",
    "#pozwala na użycie wszystkich dostępnych rdzeni procesora.\n",
    "my_n_jobs = -1\n",
    "\n",
    "#Parametr random_state to ziarno generatora liczb pseudolosowych\n",
    "\n",
    "\n",
    "#Utworzenie obiektu przykładowego modelu lasu losowego\n",
    "model2 = RandomForestClassifier(criterion=my_criterion,\n",
    "                               max_depth=my_max_depth,\n",
    "                               min_samples_split=my_min_samples_split,                                \n",
    "                               min_samples_leaf = my_min_samples_leaf,\n",
    "                               max_leaf_nodes = my_max_leaf_nodes,\n",
    "                               min_impurity_decrease = my_min_impurity_decrease,\n",
    "                               max_features = my_max_features,\n",
    "                               bootstrap = my_bootstrap,\n",
    "                               n_estimators = my_n_estimators,    \n",
    "                               random_state=0, n_jobs=my_n_jobs)\n",
    "\n",
    "#priors=[0.25,0.75] #Wersja z przekonaniem dotyczącym klasy docelowej\n",
    "#model = GaussianNB(priors)\n",
    "\n",
    "model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "\n",
    "#print(labels_predicted)\n",
    "#print(np.ravel(labels_test))\n",
    "\n",
    "\n",
    "rlabels_test = np.ravel(labels_test)\n",
    "\n",
    "suma_kosztu = 0\n",
    "for i in range(0,len(labels_test)):\n",
    "    oryg_dec = rlabels_test[i]\n",
    "    pred_dec = labels_predicted[i]\n",
    "    \n",
    "    if pred_dec==0 and oryg_dec==1:\n",
    "        suma_kosztu = suma_kosztu + 1\n",
    "    else:\n",
    "         if pred_dec==1 and oryg_dec==0:\n",
    "            suma_kosztu = suma_kosztu + 2\n",
    "            \n",
    "print(\"suma_kosztu=\",suma_kosztu)            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
